2022-07-12 13:20:35.276509: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.276685: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.276773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.276866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.276953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.277052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.277135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2022-07-12 13:20:35.277167: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
I0712 13:20:35.277503 140593426802496 train.py:67] ===========Config Dict============
I0712 13:20:35.277683 140593426802496 train.py:68] available_devices:
- 0
- 1
- 2
- 3
base_type: dual_encoder
batch_size: 4
checkpoint_freq: 10000
data_dir: google_datasets/doc_retrieval/tsv_data/
emb_dim: 128
eval_frequency: 200
factors: constant * linear_warmup * rsqrt_decay
learning_rate: 0.05
max_eval_target_length: 200
max_length: 4000
max_predict_token_length: 50
max_target_length: 200
mlp_dim: 512
model_type: reformer
num_eval_steps: 50
num_heads: 4
num_layers: 4
num_train_steps: 1001
pooling_mode: CLS
prompt: ''
qkv_dim: 128
random_seed: 0
restore_checkpoints: true
sampling_temperature: 0.6
sampling_top_k: 20
save_checkpoints: true
task_name: aan_pairs
tokenizer: char
trial: 0
vocab_file_path: google_datasets/doc_retrieval/aan/
warmup: 1000
weight_decay: 0.1

I0712 13:20:35.287002 140593426802496 xla_bridge.py:340] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0712 13:20:36.517412 140593426802496 xla_bridge.py:340] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0712 13:20:36.518112 140593426802496 xla_bridge.py:340] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0712 13:20:36.518360 140593426802496 train.py:80] GPU devices: [GpuDevice(id=0, process_index=0), GpuDevice(id=1, process_index=0), GpuDevice(id=2, process_index=0), GpuDevice(id=3, process_index=0)]
INFO:tensorflow:google_datasets/doc_retrieval/tsv_data/aan_pairs_train.tsv
I0712 13:20:36.518535 140593426802496 input_pipeline.py:32] google_datasets/doc_retrieval/tsv_data/aan_pairs_train.tsv
INFO:tensorflow:google_datasets/doc_retrieval/tsv_data/aan_pairs_eval.tsv
I0712 13:20:36.579954 140593426802496 input_pipeline.py:32] google_datasets/doc_retrieval/tsv_data/aan_pairs_eval.tsv
INFO:tensorflow:google_datasets/doc_retrieval/tsv_data/aan_pairs_test.tsv
I0712 13:20:36.612051 140593426802496 input_pipeline.py:32] google_datasets/doc_retrieval/tsv_data/aan_pairs_test.tsv
I0712 13:20:39.031786 140593426802496 input_pipeline.py:60] Data sample: OrderedDict([('label', 1.0), ('id1', b'W14-2618'), ('id2', b'C04-1200'), ('text1', b"b'1 Introduction Opinions are commonly expressed in many kinds of written and spoken text such as blogs, reviews, new articles, and conversation. Recently, there have been a surge in reserach in opinion analysis (sentiment analysis) research (Liu, 2012; Pang and Lee, 2008). While most past researches have mainly addressed explicit opinion expressions, there are a few researches for implicit opinions expressed via implicatures. Deng and Wiebe (2014) showed how sentiments toward one entity may be propagated to other entities via opinion implicature rules. Consider The bill would curb skyrocketing health care costs. Note that curb costs is bad for the object costs since the costs are reduced. We can reason that the writer is positive toward the event curb since the event is bad for the object health care costs which the writer expresses an explicit negative sentiment (skyrocketing). We can reason from there that the writer is positive toward the bill, since it is the agent of the positive event. These implicature rules involve events that positively or negatively affect the object. Such events are called malefactive and benefactive, or, for ease of writing, goodFor (gf ) and badFor (bf ) (hereafter gfbf). The list of gfbf events and their polarities (gf or bf) are necessary to develop a fully automatic opinion inference system. On first thought, one might think that we only need lists of gfbf words. However, it turns out that gfbf terms may be ambiguous ? a single word may have both gf and bf meanings. Thus, in this work, we take a sense-level approach to acquire gfbf lexicon knowledge, leading us to employ lexical resources with finegrained sense rather than word representations. For that, we adopt an automatic bootstrapping method which disambiguates gfbf polarity at the sense-level utilizing WordNet, a widely-used lexical resource. Starting from the seed set manually generated from FrameNet, a rich lexicon in which words are organized by semantic frames, we explore how gfbf terms are organized in WordNet via semantic relations and expand the seed set based on those semantic relations. The expanded lexicon is evaluated in two ways. First, the lexicon is evaluated against a corpus that has been annotated with gfbf information at the word level. Second, samples from the expanded lexicon are manually annotated at the sense level, which gives some idea of the prevalence of gfbf lexical ambiguity and provides a basis for senselevel evaluation. Also, we conduct the agreement study. The results show that the expanded lexicon covers more than half of the gfbf instances in the gfbf corpus, and the system?s accuracy, as measured against the sense-level gold standard, is substantially higher than baseline. In addition, in the agreement study, the annotators achieve good agreement, providing evidence that the annotation task is feasible and that the concept of gfbf gives us a natural coarse-grained grouping of senses. 107 2 The GFBF Corpus A corpus of blogs and editorials about the Affordable Care Act, a controversial topic, was manually annotated with gfbf information by Deng et al. (2013) 1 . This corpus provides annotated gfbf events and theagents and objects of the events. It consists of 134 blog posts and editorials. Because the Affordable Health Care Act is a controversial topic, the data is full of opinions. In this corpus, 1,411 gfbf instances are annotated, each including a gfbf event, its agent, and its object (615 gf instances and 796 bf instances). 196 different words appear in gf instances and 286 different words appear in bf instances; 10 words appear in both. 3 Sense-Level GFBF Ambiguity A word may have one or more meanings. For that, we use WordNet 2 , which is a large lexical database of English (Miller et al., 1990). In WordNet, nouns, verbs, adjectives, and adverbs are organized by semantic relations between meanings (senses). We assume that a sense is exactly one of gf, bf, or neither. Since words often have more than one sense, the polarity of a word may or may not be consistent, as the following WordNet examples show. ? A word with only gf senses: encourage S1: (v) promote, advance, boost, further, encourage (contribute to the progress or growth of) S2: (v) encourage (inspire with confidence; give hope or courage to) S3: (v) encourage (spur on) ? A word with only bf senses: assault S1: (v) assail, assault, set on, attack (attack someone physically or emotionally) S2: (v) rape, ravish, violate, assault, dishonor, dishonour, outrage (force (someone) to have sex against their will) S3: (v) attack, round, assail, lash out, snipe, assault (attack in speech or writing) All senses of encourage are good for the object, and all senses of assault are bad for the object. The polarity is always same regardless of sense. In such cases, for our purposes, which particular sense is being used does not need to be determined because any instance of the word will be good for 1 Available at http://mpqa.cs.pitt.edu/corpora/gfbf/ 2 WordNet, http://wordnet.princeton.edu/ (bad for); that is, word-level approaches can work well. However, word-level approaches are not applicable for all the words. Consider the following: ? A word with gf and neutral senses: inspire S3: (v) prompt, inspire, instigate (serve as the inciting cause of) S4: (v) cheer, root on, inspire, urge, barrack, urge on, exhort, pep up (spur on or encourage especially by cheers and shouts) S6: (v) inhale, inspire, breathe in (draw in (air)) ? A word with bf and neutral senses: neutralize S2: (v) neutralize, neutralise, nullify, negate (make ineffective by counterbalancing the effect of) S6: (v) neutralize, neutralise (make chemically neutral) The words inspire and neutralize both have 6 senses (we list a subset due to space limitations). For inspire, while S3 and S4 are good for the object, S6 doesn?t have any polarity, i.e., it is a neutral (we don?t think of inhaling air as good for the air). Also, while S2 of neutralize is bad for the object, S6 is neutral (neutralizing a solution just changes its pH). Thus, if word-level approaches are applied using these words, some neutral instances may be incorrectly classified as gf or bf events. ? A word with gf and bf senses: fight S2:(v) fight, oppose, fight back, fight down, defend (fight against or resist strongly) S4: (v) crusade, fight, press, campaign, push, agitate (exert oneself continuously, vigorously, or obtrusively to gain an end or engage in a crusade for a certain cause or person; be an advocate for) As mentioned in Section 2, 10 words are appeared in both gf and bf instances. Since only words and not senses are annotated in the corpus, such conflicts arise. These 10 words account for 9.07% (128 instances) of all annotated instances. One example is fight. In the corpus instance fight for a piece of legislation, fight is good for the object, a piece of legislation. This is S4. However, in the corpus instance we need to fight this repeal, the meaning of fight here is S2, so fight is bad for the object, this repeal. 108 Thesefore, approaches for determining the gfbf polarity of an instance that are sense-level instead of word-level promise to have higher precision. 4 Lexicon Acquisition In this section, we develop a sense-level gfbf lexicon by exploiting WordNet. The method bootstraps from a seed lexicon and iteratively follows WordNet relations. We consider only verbs. 4.1 Seed Lexicon To preserve the corpus for evaluation, we created a seed set that is independent from the corpus. An annotator who didn?t have access to the corpus manually selected gfbf words from FrameNet 3 in the light of semantic frames. The annotator found 592 gf words and 523 bf words. Decomposing each word into its senses in WordNet, there are 1,525 gf senses and 1,154 bf senses. 83 words extracted from FrameNet overlap with gfbf instances in the corpus. For independence, those words were discarded. Among the senses of the remaining words, we randomly choose 200 gf senses and 200 bf senses. 4.2 Expansion Method In WordNet, verb senses are arranged into hierarchies, that is, verb senses towards the bottom of the trees express increasingly specific manners. Thus, we can follow hypernym relations to more general senses and troponym relations to more specific verb senses. Since the troponym relation refers to a specific elaboration of a verb sense, we hypothesized that troponyms of a synset tends to have its same polarity (i.e., gf or bf). We only consider the direct troponyms in a single iteration. Although the hypernym is a more general term, we hypothesized that direct hypernyms tend to have the the same or neutral polarity, but not the opposite polarity. Also, the verb groups are promising; even though the coverage is incomplete, we expect the verb groups to be the most helpful. WordNet Similarity 4 , is a facility that provides a variety of semantic similarity and relatedness measures based on information found in the WordNet lexical database. We choose Jiang&Conrath (1997) (jcn) method which has been found to be effective for such tasks by NLP researchers. When two concetps aren?t related at all, it returns 0. The 3 FrameNet, https://framenet.icsi.berkeley.edu/fndrupal/ 4 WN Similarity, http://wn-similarity.sourceforge.net/ more they are related, the higher the value is retuned. We regarded words with similarity values greater than 1.0to be similar words. Beginning with its seed set, each lexicon (gf and bf) is expanded iteratively. On each iteration, for each sense in the current lexicon, all of its direct troponyms, direct hypernyms, and members of the same verb group are extracted and added to the lexicon for the next iteration. Similarity, for each sense, all words with above-threshold jcn values are added. For new senses that are extracted for both the gf and bf lexicons, we ignore such senses, since there is conflicting evidence (recall that we assume a sense has only one polarity, even if a word may have senses of different polarities). 4.3 Corpus Evaluation In this section, we use the gfbf annotations in the corpus as a gold standard. The annotations in the corpus are at the word level. To use the annotations as a sense-level gold standard, all the senses of a word marked gf (bf) in the corpus are considered to be gf (bf). While this is not ideal, this allows us to evaluate the lexicon against the only corpus evidence available. The 196 words that appear in gf instances in the corpus have a total of 897 senses, and the 286 words that appear in bf instances have a total of 1,154 senses. Among them, 125 senses are conflicted: a sense of a word marked gf in the corpus could be a member of the same synset as a sense of a word marked bf in the corpus. For a more reliable gold-standard set, we ignored these conflicted senses. Thus, the gold-standard set contains 772 gf senses and 1,029 bf senses. Table 1 shows the results after five iterations of lexicon expansion. In total, the gf lexicon contains 4,157 senses and the bf lexicon contains 5,071 senses. The top half gives the results for the gf lexicon and the bottom half gives the results for the bf lexicon. In the table, gfOverlap means the overlap between the senses in the lexicon in that row and the gold-standard gf set, while bfOverlap is the overlap between the senses in the lexicon in that row and the gold-standard bf set. That is, of the 772 senses in the gf gold standard, 449 (58%) are in the gf expanded lexicon while 105 (14%) are in the bf expanded lexicon. Accuracy (Acc) for gf is calculated as #gfOverlap / (#gfOverlap + #bfOverlap) and bf is calculated as #bfOverlap / (#gfOverlap + #bfOverlap). 109 goodFor #senses #gfOverlap #bfOverlap Acc Total 4,157 449 176 0.72 WN Sim 1,073 134 75 0.64 Groups 242 69 24 0.74 Troponym 4,084 226 184 0.55 Hypernym 223 75 33 0.69 badFor #senses #gfOverlap #bfOverlap Acc Total 5,071 105 562 0.84 WN Sim 1,008 34 190 0.85 Groups 255 11 86 0.89 Troponym 4,258 66 375 0.85 Hypernym 286 16 77 0.83 Table 1: Results after lexicon expansion Overall, accuracy is higher for the bf than the gf lexicon. The results in the table are broken down by semantic relation. Note that the individual counts do not sum to the totals because senses of differentwords may actually be the same sense in WordNet. The results for the bf lexicon are consistently high over all semantic relations. The results for the gf lexicon are more mixed, but all relations are valuable. The WordNet Similarity is advantageous because it detects similar senses automatically, so may provide coverage beyond the semantic relations coded in WordNet. Overall, the verb group is the most informative relation, as we suspected. Although the gf-lexicon accuracy for the troponym relation is not high, it has the advantage is that it yields the most number of senses. Its lower accuracy doesn?t support our original hypothesis. We first thought that verbs lower down in the hierarchy would tend to have the same polarity since they express specific manners characterizing an event. However, this hypothesis is wrong. Even though most troponyms have the same polarity, there are many exceptions. For example, protect#v#1, which means the first sense of the verb protect, has 18 direct troponyms such as cover for#v#1, overprotect#v#2, and so on. protect#v#1 is a gf event because the meaning is ?shielding from danger? and most troponyms are also gf events. However, overprotect#v#2, which is one of troponyms of protect#v#1, is a bf event. For the hypernym relation, the number of detected senses is not large because many were already detected in previous iterations (in general, there are fewer nodes on each level as hypernym links are traversed). 4.4 Sense Annotation Evaluation For a more direct evaluation, two annotators, who are co-authors, independently annotated a sample of senses. We randomly selected 60 words among the following classes: 10 pure gf words (i.e., all senses of the words are classified by the expansion method, and all senses are put into the gf lexicon), 10 pure bf words, 20 mixed words (i.e., all senses of the words are classified by the expansion method, and some senses are put into the gf lexicon while others are put into the bf lexicon), and 20 incomplete words (i.e., some senses of the words are not classified by the expansion method). The total number of senses is 151; 64 senses are classified as gf, 56 senses are classified as bf, and 31 senses are not classified. We included more mixed than pure words to make the results of the study more informative. Further, we wanted to included non-classified senses as decoys for the annotators. The annotators only saw the sense entries from WordNet. They didn?t know whether the system classified a sense as gf or bf or whether it didn?t classify it at all. Table 2 evaluates the lexicons against the manual annotations, and in comparison to the majority class baseline. The top half of the table shows results when treating Anno1?s annotations as the gold standard, and the bottom half shows the results when treating Anno2?s as the gold standard. Among 151 senses, Anno1 annotated 56 senses (37%) as gf, 51 senses (34%) as bf, and 44 senses (29%) as neutral. Anno2 annotated 66 senses (44%) as gf, 55 senses (36%) as bf, and 30 (20%) senses as neutral. The incorrectcases are divided into two sets: incorrect opposite consists of senses that are classified as the opposite polarity by the expansion method (e.g., the sense is classified into gf, but annotator annotates it as bf), and incorrect neutral consists of senses that the expansion method classifies as gf or bf, but the annotator marked it as neutral. We report the accuracy and the percentage of cases for each incorrect case. The accuracies substantially improve over baseline for both annotators and for both classes. In Table 3, we break down the results into gfbf classes. The gf accuracy measures the percentage of correct gf senses out of all senses annotated as gf according to the annotations (same as bf accuracy). As we can see, accuracy is higher for the bf than the gf. The conclusion is consistent with what we have discovered in Section 4.3. 110 By Anno1, 8 words are detected as mixed words, that is, they contain both gf and bf senses. By Anno2, 9 words are mixed words (this set includes the 8 mixed words of Anno1). Among the randomly selected 60 words, the proportion of mixed words range from 13.3% to 15%, according to the two annotators. This shows that gfbf lexical ambiguity does exist. To measure agreement between the annotators, we calculate two measures: percent agreement and ? (Artstein and Poesio, 2008). ? measures the amount of agreement over what is expected by chance, so it is a stricter measure. Percent agreement is 0.84 and ? is 0.75. accuracy % incorrect % incorrect baseopposite neutral line Anno1 0.53 0.16 0.32 0.37 Anno2 0.57 0.24 0.19 0.44 Table 2: Results against sense-annotated data gf accuracy bf accuracy baseline Anno1 0.74 0.83 0.37 Anno2 0.68 0.74 0.44 Table 3: Accuracy broken down for gfbf 5 Related Work Lexicons are widely used in sentiment analysis and opinion extraction. There are several previous works to acquire or expand sentiment lexicons such as (Kim and Hovy, 2004), (Strapparava and Valitutti, 2004), (Esuli and Sebastiani, 2006), (Gyamfi et al., 2009), (Mohammad and Turney, 2010) and (Peng and Park, 2011). Such sentiment lexicons are helpful for detecting explicitly stated opinions, but are not sufficient for recognizing implicit opinions. Inferred opinions often have opposite polarities from the explicit sentiment expressions in the sentence; explicit sentiments must be combined with benefactive, malefactive state and event information to detect implicit sentiments. There are few previous works closest to ours. (Feng et al., 2011) build connotation lexicons that list words with connotative polarity and connotative predicates. Goyal et al. (2010) generate a lexicon of patient polarity verbs that imparts positive or negative states on their patients. Riloff et al. (2013) learn a lexicon of negative situation phrases from a corpus of tweets with hashtag ?sarcasm?. Our work is complementary to theirs in that their acquisition methods are corpus-based, while we acquire knowledge from lexical resources. Further, all of their lexicons are word level while ours are sense level. Finally, the types of entries among the lexicons are related but not the same. Ours are specifically designed to support theautomatic recognition of implicit sentiments in text that are expressed via implicature. 6 Conclusion and Future Work In this paper, we developed a sense-level gfbf lexicon which was seeded by entries culled from FrameNet and then expanded by exploiting semantic relations in WordNet. Our evaluations show that such lexical resources are promising for expanding such sense-level lexicons. Even though the seed set is completely independent from the corpus, the expanded lexicon?s coverage of the corpus is not small. The accuracy of the expanded lexicon is substantially higher than baseline accuracy. Also, the results of the agreement study are positive, providing evidence that the annotation task is feasible and that the concept of gfbf gives us a natural coarse-grained grouping of senses. However, there is still room for improvement. We believe that gf/bf judgements of word senses could be effectively crowd-sourced; (Akkaya et al., 2010), for example, effectively used Amazon Mechanical Turk (AMT) for similar coarsegrained judgements. The idea would be to use automatic expansion methods to create a sense-level lexicon, and then have AMT workers judge the entries in which we have least confidence. This would be much more time- and cost-effective. The seed sets we used are small - only 400 total senses. We believe it will be worth the effort to create larger seed sets, with the hope to mine many additional gfbf senses from WordNet. To exploit the lexicon to recognize sentiments in a corpus, the word-sense ambiguity we discovered needs to be addressed. There is evidence that the performance of word-sense disambiguation systems using a similar coarse-grained sense inventory is much better than when the full sense inventory is used (Akkaya et al., 2009; Akkaya et al., 2011). That, coupled with the fact that our study suggests that many words are unambiguous with respect to the gfbf distinction, makes us hopeful that gfbf information may be practically exploited to improve sentiment analysis in the future. 111 7 Acknowledgments This work was supported in part by DARPA-BAA12-47 DEFT grant #12475008.'"), ('text2', b"b'1 Introduction  What is an opinion?    The many opinions on opinions are reflected  in a considerable literature (Aristotle 1954;  Perelman 1970; Toulmin et al 1979; Wallace  1975; Toulmin 2003).  Recent computational  work either focuses on sentence ?subjectivity?  (Wiebe et al 2002; Riloff et al 2003),  concentrates just on explicit statements of  evaluation, such as of films (Turney 2002; Pang  et al 2002),  or focuses on just one aspect of  opinion, e.g., (Hatzivassiloglou and McKeown  1997) on adjectives.  We wish to study opinion  in general; our work most closely resembles  that of (Yu and Hatzivassiloglou 2003).    Since an analytic definition of opinion is  probably impossible anyway, we will not  summarize past discussion or try to define  formally what is and what is not an opinion.   For our purposes, we describe an opinion as a  quadruple [Topic, Holder, Claim, Sentiment] in  which the Holder believes a Claim about the  Topic, and in many cases associates a  Sentiment, such as good or bad, with the belief.   For example, the following opinions contain  Claims but no Sentiments:   ?I believe the world is flat?   ?The Gap is likely to go bankrupt?  ?Bin Laden is hiding in Pakistan?   ?Water always flushes anti-clockwise in  the southern hemisphere?   Like Yu and Hatzivassiloglou (2003), we  want to automatically identify Sentiments,  which in this work we define as an explicit or  implicit expression in text of the Holder?s  positive, negative, or neutral regard toward the  Claim about the Topic.  (Other sentiments we  plan to study later.)  Sentiments always involve  the Holder?s emotions or desires, and may be  present explicitly or only implicitly:    ?I think that attacking Iraq would put the  US in a difficult position? (implicit)   ?The US attack on Iraq is wrong?  (explicit)   ?I like Ike? (explicit)  ?We should decrease our dependence on  oil? (implicit)    ?Reps. Tom Petri and William F.  Goodling asserted that counting illegal aliens  violates citizens? basic right to equal  representation?  (implicit)   In this paper we address the following  challenge problem.  Given a Topic (e.g.,  ?Should abortion be banned??) and a set of  texts about the topic, find the Sentiments  expressed about (claims about) the Topic (but  not its supporting subtopics) in each text, and  identify the people who hold each sentiment.   To avoid the problem of differentiating  between shades of sentiments, we simplify the  problem to: identify just expressions of  positive, negative, or neutral sentiments,  together with their holders.  In addition, for  sentences that do not express a sentiment but  simply state that some sentiment(s) exist(s),  return these sentences in a separate set.  For example, given the topic ?What should be done  with Medicare?? the sentence ?After years of  empty promises, Congress has rolled out two  Medicare prescription plans, one from House  Republicans and the other from the Democratic   Sentence POS Tagger verbs nounsAdjectives Adjective Senti ment classifier  sentiment sentiment Sentence sentiment classifier Opinion region + polarity + holder Holder finder Named Entity  Tagger Sentence Sentence texts + topic sentiment sentiment sentiment V rbs Verb Senti ment classifier  Nouns Noun Senti ment classifier  WordNet Sentence : Figure 1: System architecture.   Sens. Bob Graham of Florida and Zell Miller of  Georgia? should be returned in the separate set.    We approach the problem in stages, starting  with words and moving on to sentences.  We  take as unit sentiment carrier a single word, and  first classify each adjective, verb, and noun by  its sentiment.  We experimented with several  classifier models.  But combining sentiments  requires additional care, as Table 1 shows.    California Supreme Court agreed that the state?s  new term-limit law was constitutional.  California Supreme Court disagreed that the  state?s new term-limit law was constitutional.  California Supreme Court agreed that the state?s  new term-limit law was unconstitutional.  California Supreme Court disagreed that the  state?s new term-limit law was unconstitutional.  Table 1: Combining sentiments.   A sentence might even express opinions of  different people.  When combining word-level  sentiments, we therefore first determine for  each Holder a relevant region within the  sentence and then experiment with various  models for combining word sentiments.      We describe our models and algorithm in  Section 2, system experiments and discussion  in Section 3, and conclude in Section 4.    2 Algorithm   Given a topic and a set of texts, the system  operates in four steps.  First it selects sentences  that contain both the topic phrase and holder  candidates.  Next, the holder-based regions of  opinion are delimited.  Then the sentence  sentiment classifier calculates the polarity of all  sentiment-bearing words individually. Finally,  the system combines them to produce the  holder?s sentiment for the whole sentence.   Figure 1 shows the overall system architecture.   Section 2.1 describes the word sentiment  classifier and Section 2.2 describes the sentence  sentiment classifier.    2.1 Word Sentiment Classifier  2.1.1 Word Classification Models  For word sentiment classification we  developed two models.  The basic approach is  to assemble a small amount of seed words by  hand, sorted by polarity into two lists?positive  and negative?and then to grow this by adding  words obtained from WordNet (Miller et al  1993; Fellbaum et al 1993).  We assume  synonyms of positive words are mostly positive  and antonyms mostly negative, e.g., the  positive word ?good? hassynonyms ?virtuous,  honorable, righteous? and antonyms ?evil,  disreputable, unrighteous?.  Antonyms of  negative words are added to the positive list,  and synonyms to the negative one.    To start the seed lists we selected verbs (23  positive and 21 negative) and adjectives (15  positive and 19 negative), adding nouns later.    Since adjectives and verbs are structured  differently in WordNet, we obtained from it  synonyms and antonyms for adjectives but only  synonyms for verbs.  For each seed word, we  extracted from WordNet its expansions and  added them back into the appropriate seed lists.   Using these expanded lists, we extracted an  additional cycle of words from WordNet, to  obtain finally 5880 positive adjectives, 6233  negative adjectives, 2840 positive verbs, and  3239 negative verbs.    However, not all synonyms and antonyms  could be used: some had opposite sentiment or  were neutral.  In addition, some common words  such as ?great?, ?strong?, ?take?, and ?get?  occurred many times in both positive and  negative categories.  This indicated the need to  develop a measure of strength of sentiment  polarity (the alternative was simply to discard  such ambiguous words)?to determine how  strongly a word is positive and also how  strongly it is negative.  This would enable us to  discard sentiment-ambiguous words but retain  those with strengths over some threshold.    Armed with such a measure, we can also  assign strength of sentiment polarity to as yet  unseen words.  Given a new word, we use  WordNet again to obtain a synonym set of the  unseen word to determine how it interacts with  our sentiment seed lists.  That is, we compute   (1)                 ).....,|(maxarg )|(maxarg 21 n c c synsynsyncP wcP ? where c is a sentiment category (positive or  negative), w is the unseen word, and synn are the  WordNet synonyms of w.  To compute  Equation (1), we tried two different models:   (2)   )|()(maxarg )|()(maxarg )|()(maxarg)|(maxarg 1 ))(,(  ...3 2 1 ? = = = = m k wsynsetfcount k c n c cc kcfPcP csynsynsynsynPcP cwPcPwcP where fk is the kth feature (list word) of  sentiment class c which is also a member of the  synonym set of w, and count(fk,synset(w)) is the  total number of occurrences of fk in the  synonym set of w.  P(c) is the number of words  in class c divided by the total number of words  considered.  This model derives from document  classification.  We used the synonym and  antonym lists obtained from Wordnet instead of  learning word sets from a corpus, since the  former is simpler and does not require  manually annotated data for training.   Equation (3) shows the second model for a  word sentiment classifier.    (3)         )( ),( )(maxarg )|()(maxarg)|(maxarg 1 ccount csyncount cP cwPcPwcP n i i c cc ? == =   To compute the probability P(w|c) of word w  given a sentiment class c, we count the  occurrence of w?s synonyms in the list of c.   The intuition is that the more synonyms  occuring in c, the more likely the word belongs.    We computed both positive and negative  sentiment strengths for each word and  compared their relative magnitudes.  Table 2  shows several examples of the system output,  computed with Equation (2), in which ?+?  represents positive category strength and ?-?  negative.  The word ?amusing?, for example,  was classified as carrying primarily positive  sentiment, and ?blame? as primarily negative.   The absolute value of each category represents  the strength of its sentiment polarity.  For  instance, ?afraid? with strength -0.99 represents  strong negavitity while ?abysmal? with strength  -0.61 represents weaker negativity.    abysmal : NEGATIVE    [+ : 0.3811][- : 0.6188]  adequate : POSITIVE     [+ : 0.9999][- : 0.0484e-11]  afraid : NEGATIVE      [+ : 0.0212e-04][- : 0.9999]  ailing : NEGATIVE      [+ : 0.0467e-8][- : 0.9999]  amusing : POSITIVE     [+ : 0.9999][- : 0.0593e-07]  answerable : POSITIVE    [+ : 0.8655][- : 0.1344]  apprehensible: POSITIVE    [+ : 0.9999][- : 0.0227e-07]  averse : NEGATIVE       [+ : 0.0454e-05][- : 0.9999]  blame : NEGATIVE       [+ : 0.2530][- : 0.7469]  Table 2: Sample output of word sentiment  classifier.   2.2 Sentence Sentiment Classifier  As shows in Table 1, combining sentiments  in a sentence can be tricky.  We are interested  in the sentiments of the Holder about the  Claim.  Manual analysis showed that such  sentiments can be found most reliably close to  the Holder; without either Holder or  Topic/Claim nearby as anchor points, even  humans sometimes have trouble reliably  determining the source of a sentiment.  We  therefore included in the algorithm steps to  identify the Topic (through direct matching,  since we took it as given) and any likely  opinion Holders (see Section 2.2.1).  Near each  Holder we then identified a region in which  sentiments would be considered; any  sentiments outside such a region we take to be  of undetermined origin and ignore (Section  2.2.2).  We then defined several models for  combining the sentiments expressed within a  region (Section 2.2.3).    2.2.1 Holder Identification  We used BBN?s named entity tagger  IdentiFinder to identify potentialholders of an  opinion.  We considered PERSON and  ORGANIZATION as the only possible opinion  holders.  For sentences with more than one  Holder, we chose the one closest to the Topic  phrase, for simplicity.  This is a very crude step.   A more sophisticated approach would employ a  parser to identify syntactic relationships  between each Holder and all dependent  expressions of sentiment.    2.2.2 Sentiment Region  Lacking a parse of the sentence, we were  faced with a dilemma: How large should a  region be?  We therefore defined the sentiment  region in various ways (see Table 3) and  experimented with their effectiveness, as  reported in Section 3.    Window1: full sentence  Window2: words between Holder and Topic  Window3: window2 ? 2 words  Window4: window2 to the end of sentence  Table 3: Four variations of region size.  2.2.3 Classification Models  We built three models to assign a sentiment  category to a given sentence, each combining  the individual sentiments of sentiment-bearing  words, as described above, in a different way.    Model 0 simply considers the polarities of  the sentiments, not the strengths:   Model 0: ? (signs in region)  The intuition here is something like  ?negatives cancel one another out?.  Here the  system assigns the same sentiment to both ?the  California Supreme Court agreed that the  state?s new term-limit law was constitutional?  and ?the California Supreme Court disagreed  that the state?s new term-limit law was  unconstitutional?.  For this model, we also  included negation words such as not and never  to reverse the sentiment polarity.    Model 1 is the harmonic mean (average) of  the sentiment strengths in the region:   Model 1:  cwcp wcp cn scP ij n i i = = ? = )|(argmax if  ,)|( )( 1)|( j 1   Here n(c) is the number of words in the region  whose sentiment category is c.  If a region  contains more and stronger positive than  negative words, the sentiment will be positive.    Model 2 is the geometric mean:   Model 2:  cwcpif wcpscP ij n i i cn = ?= ? = ? )|(argmax  ,)|(10)|( j 1 1)(   2.2.4 Examples  The following are two example outputs.      Public officials throughout California have  condemned a U.S. Senate vote Thursday to  exclude illegal aliens from the 1990 census,  saying the action will shortchange California in  Congress and possibly deprive the state of  millions of dollars of federal aid for medical  emergency services and other programs for poor  people.  TOPIC : illegal alien  HOLDER : U.S. Senate  OPINION REGION: vote/NN Thursday/NNP      to/TO exclude/VB illegal/JJ aliens/NNS from/IN  the/DT 1990/CD census,/NN  SENTIMENT_POLARITY: negative   For that reason and others, the Constitutional  Convention unanimously rejected term limits  and the First Congress soundly defeated two  subsequent term-limit proposals.  TOPIC : term limit  HOLDER : First Congress  OPINION REGION: soundly/RB defeated/VBD  two/CD subsequent/JJ term-limit/JJ  proposals./NN  SENTIMENT_POLARITY: negative  3 Experiments  The first experiment examines the two word  sentiment classifier models and the second the  three sentence sentiment classifier models.    3.1 Word Sentiment Classifier  For test material, we asked three humans to  classify data.  We started with a basic English  word list for foreign students preparing for the  TOEFL test and intersected it with an adjective  list containing 19748 English adjectives and a  verb list of 8011 verbs to obtain common  adjectives and verbs.  From this we randomly  selected 462 adjectives and 502 verbs for  human classification.  Human1 and human2  each classified 462 adjectives, and human2 and  human3 502 verbs.    The classification task is defined as assigning  each word to one of three categories: positive,  negative, and neutral.   3.1.1 Human?Human Agreement    Adjectives Verbs   Human1 : Human2 Human1 : Human3 Strict 76.19% 62.35%  Lenient 88.96% 85.06%  Table 4: Inter-human classification  agreement.  Table 4 shows inter-human agreement.  The  strict measure is defined over all three  categories, whereas the lenient measure is taken  over only two categories, where positive and  neutral have been merged, should we choose to  focus only on differentiating words of negative  sentiment.    3.1.2 Human?Machine Agreement  Table 5 shows results, using Equation (2) of  Section 2.1.1, compared against a baseline that  randomly assigns a sentiment category to each  word (averaged over 10 iterations).  The system  achieves lower agreement than humans but  higher than the random process.    Of the test data, the algorithm classified  93.07% of adjectives and 83.27% of verbs as  either positive and negative.  The remainder of  adjectives and verbs failed to be classified,  since they did not overlap with the synonym set  of adjectives and verbs.    In Table 5, the seed list included just a few  manually selected seed words (23 positive and  21 negative verbs and 15 and 19 adjectives,  repectively).  We decided to investigate the  effect of more seed words.   After collecting the  annotated data, we added half of it (231  adjectives and 251 verbs) to the training set,  retaining the other half for the test.  As Table 6  shows, agreement of both adjectives and verbs  with humans improves.  Recall is also  improved.   Adjective  (Train: 231  Test : 231)  Verb  (Train: 251  Test : 251)  Lenient agreement Lenient agreement  H1:M H2:M  recall H1:M H3:M  recall  75.66% 77.88% 97.84% 81.20% 79.06% 93.23% Table 6: Results including manual data.    3.2 Sentence Sentiment Classifier  3.2.1 Data  100 sentences were selected from the DUC  2001 corpus with the topics ?illegal alien?,  ?term limits?, ?gun control?, and ?NAFTA?.   Two humans annotated the 100 sentences with  three categories (positive, negative, and N/A).   To measure the agreement between humans, we  used the Kappa statistic (Siegel and Castellan  Jr. 1988).  The Kappa value for the annotation  task of 100 sentences was 0.91, which is  considered to be reliable.    3.2.2 Test on Human Annotated Data  We experimented on Section 2.2.3?s 3  models of sentiment classifiers, using the 4  different window definitions and 4 variations of  word-level classifiers (the two word sentiment  equations introduced in Section 2.1.1, first with  and then without normalization, to compare  performance).    Since Model 0 considers not probabilities of  words but only their polarities, the two word-  level classifier equations yield the same results.  Consequently, Model 0 has 8 combinations and  Models 1 and 2 have 16 each.     To test the identification of opinion Holder,  we first ran models with holders that were  annotated by humans then ran the same models  with the automatic holder finding strategies.   The results appear in Figures 2 and 3. The  models are numbered as follows: m0 through  m4 represent 4 sentence classifier models, Table 5. Agreement between humans and system.    Adjective  (test: 231 adjectives) Verb (test : 251 verbs)  Lenient agreement Lenient agreement    H1:M H2:M  recall  H1:M H3:M  recall   Random selection  (average of 10 iterations) 59.35% 57.81% 100% 59.02% 56.59% 100%  Basic method 68.37% 68.60% 93.07% 75.84% 72.72% 83.27%  p1/p2 and p3/p4 represent the word classifier  models in Equation (2) and Equation (3) with  normalization and without normalization  respectively.  0.3 0.4 0.5 0.6 0.7 0.8 0.9 m0p1 m0p3 m1p1 m1p2 m1p3 m1p4 m2p1 m2p2 m2p3 m2p4 ac cu ra cy Window 1 Window 2 Window 3 Window 4 0.3 0.4 0.5 0.6 0.7 0.8 0.9 m0p1 m0p3 m1p1 m1p2 m1p3 m1p4 m2p1 m2p2 m2p3 m2p4 ac cu rac y Window 1 Window 2 Window 3 Window 4 Human 1 : Machine Human 2 : Machine Figure 2: Results with manually annotated  Holder.  0.3 0.4 0.5 0.6 0.7 0.8 0.9 m0p1 m0p3 m1p1 m1p2 m1p3 m1p4 m2p1 m2p2 m2p3 m2p4 ac cu rac y Window 1 Window 2 Window 3 Window 4 0.3 0.4 0.5 0.6 0.7 0.8 0.9 m0p1 m0p3 m1p1 m1p2 m1p3 m1p4 m2p1 m2p2 m2p3 m2p4 ac cu rac y Window 1 Window 2 Window 3 Window 4 Human 1 : Machine Human 2 : Machine Figure 3: Results with automatic Holder  detection.  Correctness of an opinion is determined when the system finds both a correct holder and  the appropriate sentiment within the sentence.   Since human1 classified 33 sentences positive  and 33 negative, random classification gives 33  out of 66 sentences.  Similarly, since human2  classified 29 positive and 34 negative, random  classification gives 34 out of 63 when the  system blindly marks all sentences as negative  and 29 out of 63 when it marks all as positive.   The system?s best model performed at 81%  accuracy with the manually provided holder  and at 67% accuracy with automatic holder  detection.    3.3 Problems  3.3.1 Word Sentiment Classification  As mentioned, some words have both strong  positive and negative sentiment.  For these  words, it is difficult to pick one sentiment  category without considering context.  Second,  a unigram model is not sufficient: common  words without much sentiment alone can  combine to produce reliable sentiment.  For  example, in ??Term limits really hit at  democracy,? says Prof. Fenno?, the common  and multi-meaning word ?hit? was used to  express a negative point of view about term  limits.  If such combinations occur adjacently,  we can use bigrams or trigrams in the seed  word list.  When they occur at a distance,  however, it is more difficult to identify the  sentiment correctly, especially if one of the  words falls outside the sentiment region.    3.3.2 Sentence Sentiment Classification  Even in a single sentence, a holder might  express two different opinions. Our system  only detects the closest one.    Another difficult problem is that the models  cannot infer sentiments from facts in a  sentence.  ?She thinks term limits will give  women more opportunities in politics?  expresses a positive opinion about term limits  but the absence of adjective, verb, and noun  sentiment-words prevents a classification.    Although relatively easy task for people,  detecting an opinion holder is not simple either.   As a result, our system sometimes picks a  wrong holder when there are multiple plausible  opinion holder candidates present.   Employing  a parser to delimit opinion regions and more  accurately associate them with potential holders  should help.    3.4 Discussion  Which combination of models is best?  The best overall performance is provided by  Model 0.  Apparently, the mere presence of  negative words is more important than  sentiment strength.  For manually tagged holder  and topic, Model 0 has the highest single  performance, though Model 1 averages best.    Which is better, a sentence or a region?   With manually identified topic and holder,  the region window4 (from Holder to sentence  end) performs better than other regions.    How do scores differ from manual to  automatic holder identification?  Table 7 comparesthe average results with  automatic holder identification to manually  annotated holders in 40 different models.   Around 7 more sentences (around 11%) were  misclassified by the automatic detection  method.      positive negative total  Human1 5.394 1.667 7.060  Human2 4.984 1.714 6.698  Table 7: Average difference between  manual and automatic holder detection.  How does adding the neutral sentiment as a  separate category affect the score?  It is very confusing even for humans to  distinguish between a neutral opinion and nonopinion bearing sentences.  In previous  research, we built a sentence subjectivity  classifier.  Unfortunately, in most cases it  classifies neutral and weak sentiment sentences  as non-opinion bearing sentences.   4 Conclusion  Sentiment recognition is a challenging and  difficult part of understanding opinions.  We  plan to extend our work to more difficult cases  such as sentences with weak-opinion-bearing  words or sentences with multiple opinions  about a topic.  To improve identification of the  Holder, we plan to use a parser to associate  regions more reliably with holders.  We plan to  explore other learning techniques, such as  decision lists or SVMs.    Nonetheless, as the experiments show,  encouraging results can be obtained even with  relatively simple models and only a small  amount of manual seeding effort.     '")])
INFO:tensorflow:Finished getting dataset.
I0712 13:20:39.092945 140593426802496 input_pipeline.py:91] Finished getting dataset.
I0712 13:20:39.093176 140593426802496 input_pipeline.py:94] Using char-level/byte dataset..
I0712 13:20:39.234267 140593426802496 train.py:106] Vocab Size: 257
I0712 13:20:51.854828 140593426802496 checkpoints.py:242] Found no checkpoint directory at trained_models/matching/reformer
I0712 13:20:52.481652 140593426802496 train_utils.py:370] Starting training
I0712 13:20:52.481836 140593426802496 train_utils.py:371] ====================
I0712 13:21:36.051307 140593426802496 train_utils.py:377] train in step: 0
I0712 13:21:36.082901 140593426802496 train_utils.py:377] train in step: 1
I0712 13:21:36.112624 140593426802496 train_utils.py:377] train in step: 2
I0712 13:21:36.168254 140593426802496 train_utils.py:377] train in step: 3
I0712 13:21:36.223984 140593426802496 train_utils.py:377] train in step: 4
I0712 13:21:36.279664 140593426802496 train_utils.py:377] train in step: 5
I0712 13:21:36.337095 140593426802496 train_utils.py:377] train in step: 6
I0712 13:21:36.396088 140593426802496 train_utils.py:377] train in step: 7
I0712 13:21:36.454072 140593426802496 train_utils.py:377] train in step: 8
I0712 13:21:36.508071 140593426802496 train_utils.py:377] train in step: 9
I0712 13:21:36.561029 140593426802496 train_utils.py:377] train in step: 10
I0712 13:21:36.614024 140593426802496 train_utils.py:377] train in step: 11
I0712 13:21:36.677730 140593426802496 train_utils.py:377] train in step: 12
I0712 13:21:36.729324 140593426802496 train_utils.py:377] train in step: 13
I0712 13:21:36.782054 140593426802496 train_utils.py:377] train in step: 14
I0712 13:21:36.838100 140593426802496 train_utils.py:377] train in step: 15
I0712 13:21:36.888942 140593426802496 train_utils.py:377] train in step: 16
I0712 13:21:36.941018 140593426802496 train_utils.py:377] train in step: 17
I0712 13:21:36.993922 140593426802496 train_utils.py:377] train in step: 18
I0712 13:21:37.046558 140593426802496 train_utils.py:377] train in step: 19
I0712 13:21:37.103439 140593426802496 train_utils.py:377] train in step: 20
I0712 13:21:37.154666 140593426802496 train_utils.py:377] train in step: 21
I0712 13:21:37.206931 140593426802496 train_utils.py:377] train in step: 22
I0712 13:21:37.260152 140593426802496 train_utils.py:377] train in step: 23
I0712 13:21:37.312588 140593426802496 train_utils.py:377] train in step: 24
I0712 13:21:37.365237 140593426802496 train_utils.py:377] train in step: 25
I0712 13:21:37.418407 140593426802496 train_utils.py:377] train in step: 26
I0712 13:21:37.470970 140593426802496 train_utils.py:377] train in step: 27
I0712 13:21:37.523766 140593426802496 train_utils.py:377] train in step: 28
I0712 13:21:37.576315 140593426802496 train_utils.py:377] train in step: 29
I0712 13:21:37.629548 140593426802496 train_utils.py:377] train in step: 30
I0712 13:21:37.682193 140593426802496 train_utils.py:377] train in step: 31
I0712 13:21:37.736105 140593426802496 train_utils.py:377] train in step: 32
I0712 13:21:37.789370 140593426802496 train_utils.py:377] train in step: 33
I0712 13:21:37.841648 140593426802496 train_utils.py:377] train in step: 34
I0712 13:21:37.894810 140593426802496 train_utils.py:377] train in step: 35
I0712 13:21:37.946849 140593426802496 train_utils.py:377] train in step: 36
I0712 13:21:37.999596 140593426802496 train_utils.py:377] train in step: 37
I0712 13:21:38.052731 140593426802496 train_utils.py:377] train in step: 38
I0712 13:21:38.105489 140593426802496 train_utils.py:377] train in step: 39
I0712 13:21:38.157860 140593426802496 train_utils.py:377] train in step: 40
I0712 13:21:38.210840 140593426802496 train_utils.py:377] train in step: 41
I0712 13:21:38.263442 140593426802496 train_utils.py:377] train in step: 42
I0712 13:21:38.316528 140593426802496 train_utils.py:377] train in step: 43
I0712 13:21:38.369752 140593426802496 train_utils.py:377] train in step: 44
I0712 13:21:38.422681 140593426802496 train_utils.py:377] train in step: 45
I0712 13:21:38.475503 140593426802496 train_utils.py:377] train in step: 46
I0712 13:21:38.527854 140593426802496 train_utils.py:377] train in step: 47
I0712 13:21:38.580897 140593426802496 train_utils.py:377] train in step: 48
I0712 13:21:38.633427 140593426802496 train_utils.py:377] train in step: 49
I0712 13:21:38.687454 140593426802496 train_utils.py:377] train in step: 50
I0712 13:21:38.739820 140593426802496 train_utils.py:377] train in step: 51
I0712 13:21:38.793653 140593426802496 train_utils.py:377] train in step: 52
I0712 13:21:38.846365 140593426802496 train_utils.py:377] train in step: 53
I0712 13:21:38.898403 140593426802496 train_utils.py:377] train in step: 54
I0712 13:21:38.956198 140593426802496 train_utils.py:377] train in step: 55
I0712 13:21:39.007834 140593426802496 train_utils.py:377] train in step: 56
I0712 13:21:39.063944 140593426802496 train_utils.py:377] train in step: 57
I0712 13:21:39.116479 140593426802496 train_utils.py:377] train in step: 58
I0712 13:21:39.169351 140593426802496 train_utils.py:377] train in step: 59
I0712 13:21:39.222028 140593426802496 train_utils.py:377] train in step: 60
I0712 13:21:39.276136 140593426802496 train_utils.py:377] train in step: 61
I0712 13:21:39.327099 140593426802496 train_utils.py:377] train in step: 62
I0712 13:21:39.379919 140593426802496 train_utils.py:377] train in step: 63
I0712 13:21:39.435311 140593426802496 train_utils.py:377] train in step: 64
I0712 13:21:39.487404 140593426802496 train_utils.py:377] train in step: 65
I0712 13:21:39.540172 140593426802496 train_utils.py:377] train in step: 66
I0712 13:21:39.596545 140593426802496 train_utils.py:377] train in step: 67
I0712 13:21:39.648587 140593426802496 train_utils.py:377] train in step: 68
I0712 13:21:39.701227 140593426802496 train_utils.py:377] train in step: 69
I0712 13:21:39.755653 140593426802496 train_utils.py:377] train in step: 70
I0712 13:21:39.808440 140593426802496 train_utils.py:377] train in step: 71
I0712 13:21:39.861123 140593426802496 train_utils.py:377] train in step: 72
I0712 13:21:39.916282 140593426802496 train_utils.py:377] train in step: 73
I0712 13:21:39.968934 140593426802496 train_utils.py:377] train in step: 74
I0712 13:21:40.021596 140593426802496 train_utils.py:377] train in step: 75
I0712 13:21:40.075344 140593426802496 train_utils.py:377] train in step: 76
I0712 13:21:40.126776 140593426802496 train_utils.py:377] train in step: 77
I0712 13:21:40.179673 140593426802496 train_utils.py:377] train in step: 78
I0712 13:21:40.232933 140593426802496 train_utils.py:377] train in step: 79
I0712 13:21:40.285799 140593426802496 train_utils.py:377] train in step: 80
I0712 13:21:40.341503 140593426802496 train_utils.py:377] train in step: 81
I0712 13:21:40.395086 140593426802496 train_utils.py:377] train in step: 82
I0712 13:21:40.448132 140593426802496 train_utils.py:377] train in step: 83
I0712 13:21:40.505109 140593426802496 train_utils.py:377] train in step: 84
I0712 13:21:40.558936 140593426802496 train_utils.py:377] train in step: 85
I0712 13:21:40.612408 140593426802496 train_utils.py:377] train in step: 86
I0712 13:21:40.666223 140593426802496 train_utils.py:377] train in step: 87
I0712 13:21:40.719251 140593426802496 train_utils.py:377] train in step: 88
I0712 13:21:40.773141 140593426802496 train_utils.py:377] train in step: 89
I0712 13:21:40.826789 140593426802496 train_utils.py:377] train in step: 90
I0712 13:21:40.882675 140593426802496 train_utils.py:377] train in step: 91
I0712 13:21:40.938102 140593426802496 train_utils.py:377] train in step: 92
I0712 13:21:40.991196 140593426802496 train_utils.py:377] train in step: 93
I0712 13:21:41.045410 140593426802496 train_utils.py:377] train in step: 94
I0712 13:21:41.099685 140593426802496 train_utils.py:377] train in step: 95
I0712 13:21:41.152543 140593426802496 train_utils.py:377] train in step: 96
I0712 13:21:41.206343 140593426802496 train_utils.py:377] train in step: 97
I0712 13:21:41.260455 140593426802496 train_utils.py:377] train in step: 98
I0712 13:21:41.313565 140593426802496 train_utils.py:377] train in step: 99
I0712 13:21:41.369199 140593426802496 train_utils.py:377] train in step: 100
I0712 13:21:41.420766 140593426802496 train_utils.py:377] train in step: 101
I0712 13:21:41.474357 140593426802496 train_utils.py:377] train in step: 102
I0712 13:21:41.527894 140593426802496 train_utils.py:377] train in step: 103
I0712 13:21:41.582047 140593426802496 train_utils.py:377] train in step: 104
I0712 13:21:41.635331 140593426802496 train_utils.py:377] train in step: 105
I0712 13:21:41.689265 140593426802496 train_utils.py:377] train in step: 106
I0712 13:21:41.743020 140593426802496 train_utils.py:377] train in step: 107
I0712 13:21:41.798610 140593426802496 train_utils.py:377] train in step: 108
I0712 13:21:41.850259 140593426802496 train_utils.py:377] train in step: 109
I0712 13:21:41.904120 140593426802496 train_utils.py:377] train in step: 110
I0712 13:21:41.957966 140593426802496 train_utils.py:377] train in step: 111
I0712 13:21:42.011313 140593426802496 train_utils.py:377] train in step: 112
I0712 13:21:42.065097 140593426802496 train_utils.py:377] train in step: 113
I0712 13:21:42.120773 140593426802496 train_utils.py:377] train in step: 114
I0712 13:21:42.174128 140593426802496 train_utils.py:377] train in step: 115
I0712 13:21:42.226926 140593426802496 train_utils.py:377] train in step: 116
I0712 13:21:42.281004 140593426802496 train_utils.py:377] train in step: 117
I0712 13:21:42.335603 140593426802496 train_utils.py:377] train in step: 118
I0712 13:21:42.389678 140593426802496 train_utils.py:377] train in step: 119
I0712 13:21:42.443382 140593426802496 train_utils.py:377] train in step: 120
I0712 13:21:42.496596 140593426802496 train_utils.py:377] train in step: 121
I0712 13:21:42.550801 140593426802496 train_utils.py:377] train in step: 122
I0712 13:21:42.603824 140593426802496 train_utils.py:377] train in step: 123
I0712 13:21:42.657812 140593426802496 train_utils.py:377] train in step: 124
I0712 13:21:42.713016 140593426802496 train_utils.py:377] train in step: 125
I0712 13:21:42.767109 140593426802496 train_utils.py:377] train in step: 126
I0712 13:21:42.820448 140593426802496 train_utils.py:377] train in step: 127
I0712 13:21:42.874170 140593426802496 train_utils.py:377] train in step: 128
I0712 13:21:42.927678 140593426802496 train_utils.py:377] train in step: 129
I0712 13:21:42.981620 140593426802496 train_utils.py:377] train in step: 130
I0712 13:21:43.035628 140593426802496 train_utils.py:377] train in step: 131
I0712 13:21:43.089027 140593426802496 train_utils.py:377] train in step: 132
I0712 13:21:43.142544 140593426802496 train_utils.py:377] train in step: 133
I0712 13:21:43.196405 140593426802496 train_utils.py:377] train in step: 134
I0712 13:21:43.250924 140593426802496 train_utils.py:377] train in step: 135
I0712 13:21:43.304158 140593426802496 train_utils.py:377] train in step: 136
I0712 13:21:43.358067 140593426802496 train_utils.py:377] train in step: 137
I0712 13:21:43.414691 140593426802496 train_utils.py:377] train in step: 138
I0712 13:21:43.468176 140593426802496 train_utils.py:377] train in step: 139
I0712 13:21:43.521840 140593426802496 train_utils.py:377] train in step: 140
I0712 13:21:43.575630 140593426802496 train_utils.py:377] train in step: 141
I0712 13:21:43.630418 140593426802496 train_utils.py:377] train in step: 142
I0712 13:21:43.683453 140593426802496 train_utils.py:377] train in step: 143
I0712 13:21:43.737365 140593426802496 train_utils.py:377] train in step: 144
I0712 13:21:43.791881 140593426802496 train_utils.py:377] train in step: 145
I0712 13:21:43.846060 140593426802496 train_utils.py:377] train in step: 146
I0712 13:21:43.901008 140593426802496 train_utils.py:377] train in step: 147
I0712 13:21:43.954386 140593426802496 train_utils.py:377] train in step: 148
I0712 13:21:44.008991 140593426802496 train_utils.py:377] train in step: 149
I0712 13:21:44.062626 140593426802496 train_utils.py:377] train in step: 150
I0712 13:21:44.115908 140593426802496 train_utils.py:377] train in step: 151
I0712 13:21:44.172359 140593426802496 train_utils.py:377] train in step: 152
I0712 13:21:44.225599 140593426802496 train_utils.py:377] train in step: 153
I0712 13:21:44.279368 140593426802496 train_utils.py:377] train in step: 154
I0712 13:21:44.335984 140593426802496 train_utils.py:377] train in step: 155
I0712 13:21:44.397666 140593426802496 train_utils.py:377] train in step: 156
I0712 13:21:44.451833 140593426802496 train_utils.py:377] train in step: 157
I0712 13:21:44.505171 140593426802496 train_utils.py:377] train in step: 158
I0712 13:21:44.560638 140593426802496 train_utils.py:377] train in step: 159
I0712 13:21:44.614583 140593426802496 train_utils.py:377] train in step: 160
I0712 13:21:44.669057 140593426802496 train_utils.py:377] train in step: 161
I0712 13:21:44.725163 140593426802496 train_utils.py:377] train in step: 162
I0712 13:21:44.776403 140593426802496 train_utils.py:377] train in step: 163
I0712 13:21:44.830896 140593426802496 train_utils.py:377] train in step: 164
I0712 13:21:44.884091 140593426802496 train_utils.py:377] train in step: 165
I0712 13:21:44.938813 140593426802496 train_utils.py:377] train in step: 166
I0712 13:21:44.995427 140593426802496 train_utils.py:377] train in step: 167
I0712 13:21:45.058831 140593426802496 train_utils.py:377] train in step: 168
I0712 13:21:45.116102 140593426802496 train_utils.py:377] train in step: 169
I0712 13:21:45.171541 140593426802496 train_utils.py:377] train in step: 170
I0712 13:21:45.222787 140593426802496 train_utils.py:377] train in step: 171
I0712 13:21:45.280885 140593426802496 train_utils.py:377] train in step: 172
I0712 13:21:45.334386 140593426802496 train_utils.py:377] train in step: 173
I0712 13:21:45.387688 140593426802496 train_utils.py:377] train in step: 174
I0712 13:21:45.441539 140593426802496 train_utils.py:377] train in step: 175
I0712 13:21:45.495432 140593426802496 train_utils.py:377] train in step: 176
I0712 13:21:45.548812 140593426802496 train_utils.py:377] train in step: 177
I0712 13:21:45.603001 140593426802496 train_utils.py:377] train in step: 178
I0712 13:21:45.656744 140593426802496 train_utils.py:377] train in step: 179
I0712 13:21:45.710210 140593426802496 train_utils.py:377] train in step: 180
I0712 13:21:45.767522 140593426802496 train_utils.py:377] train in step: 181
I0712 13:21:45.823628 140593426802496 train_utils.py:377] train in step: 182
I0712 13:21:45.876783 140593426802496 train_utils.py:377] train in step: 183
I0712 13:21:45.930124 140593426802496 train_utils.py:377] train in step: 184
I0712 13:21:45.984356 140593426802496 train_utils.py:377] train in step: 185
I0712 13:21:46.037602 140593426802496 train_utils.py:377] train in step: 186
I0712 13:21:46.091485 140593426802496 train_utils.py:377] train in step: 187
I0712 13:21:46.145513 140593426802496 train_utils.py:377] train in step: 188
I0712 13:21:46.201359 140593426802496 train_utils.py:377] train in step: 189
I0712 13:21:46.254967 140593426802496 train_utils.py:377] train in step: 190
I0712 13:21:46.309366 140593426802496 train_utils.py:377] train in step: 191
I0712 13:21:46.376917 140593426802496 train_utils.py:377] train in step: 192
I0712 13:21:46.435127 140593426802496 train_utils.py:377] train in step: 193
I0712 13:21:46.493201 140593426802496 train_utils.py:377] train in step: 194
I0712 13:21:46.548159 140593426802496 train_utils.py:377] train in step: 195
I0712 13:21:46.605004 140593426802496 train_utils.py:377] train in step: 196
I0712 13:21:46.659352 140593426802496 train_utils.py:377] train in step: 197
I0712 13:21:46.713195 140593426802496 train_utils.py:377] train in step: 198
I0712 13:21:46.766906 140593426802496 train_utils.py:377] train in step: 199
I0712 13:21:46.821184 140593426802496 train_utils.py:377] train in step: 200
I0712 13:21:47.528238 140593426802496 train_utils.py:396] train in step: 200, loss: 0.7378999590873718, acc: 0.5322999954223633
I0712 13:22:10.068130 140593426802496 train_utils.py:411] eval in step: 200, loss: 0.6871, acc: 0.5600
I0712 13:22:10.072946 140593426802496 train_utils.py:421] Testing...
I0712 13:22:13.558455 140593426802496 train_utils.py:424] test in step: 200, loss: 0.6907, acc: 0.5450
I0712 13:22:13.596758 140593426802496 train_utils.py:377] train in step: 201
I0712 13:22:13.627467 140593426802496 train_utils.py:377] train in step: 202
I0712 13:22:13.673696 140593426802496 train_utils.py:377] train in step: 203
I0712 13:22:13.738324 140593426802496 train_utils.py:377] train in step: 204
I0712 13:22:13.792512 140593426802496 train_utils.py:377] train in step: 205
I0712 13:22:13.851707 140593426802496 train_utils.py:377] train in step: 206
I0712 13:22:13.903112 140593426802496 train_utils.py:377] train in step: 207
I0712 13:22:13.957139 140593426802496 train_utils.py:377] train in step: 208
I0712 13:22:14.012058 140593426802496 train_utils.py:377] train in step: 209
I0712 13:22:14.065675 140593426802496 train_utils.py:377] train in step: 210
I0712 13:22:14.119198 140593426802496 train_utils.py:377] train in step: 211
I0712 13:22:14.173664 140593426802496 train_utils.py:377] train in step: 212
I0712 13:22:14.228173 140593426802496 train_utils.py:377] train in step: 213
I0712 13:22:14.285426 140593426802496 train_utils.py:377] train in step: 214
I0712 13:22:14.335882 140593426802496 train_utils.py:377] train in step: 215
I0712 13:22:14.389633 140593426802496 train_utils.py:377] train in step: 216
I0712 13:22:14.445169 140593426802496 train_utils.py:377] train in step: 217
I0712 13:22:14.501047 140593426802496 train_utils.py:377] train in step: 218
I0712 13:22:14.554885 140593426802496 train_utils.py:377] train in step: 219
I0712 13:22:14.609308 140593426802496 train_utils.py:377] train in step: 220
I0712 13:22:14.662555 140593426802496 train_utils.py:377] train in step: 221
I0712 13:22:14.718790 140593426802496 train_utils.py:377] train in step: 222
I0712 13:22:14.774255 140593426802496 train_utils.py:377] train in step: 223
I0712 13:22:14.827331 140593426802496 train_utils.py:377] train in step: 224
I0712 13:22:14.882828 140593426802496 train_utils.py:377] train in step: 225
I0712 13:22:14.936201 140593426802496 train_utils.py:377] train in step: 226
I0712 13:22:14.990302 140593426802496 train_utils.py:377] train in step: 227
I0712 13:22:15.043626 140593426802496 train_utils.py:377] train in step: 228
I0712 13:22:15.099981 140593426802496 train_utils.py:377] train in step: 229
I0712 13:22:15.153967 140593426802496 train_utils.py:377] train in step: 230
I0712 13:22:15.211835 140593426802496 train_utils.py:377] train in step: 231
I0712 13:22:15.265970 140593426802496 train_utils.py:377] train in step: 232
I0712 13:22:15.319500 140593426802496 train_utils.py:377] train in step: 233
I0712 13:22:15.372884 140593426802496 train_utils.py:377] train in step: 234
I0712 13:22:15.428797 140593426802496 train_utils.py:377] train in step: 235
I0712 13:22:15.481798 140593426802496 train_utils.py:377] train in step: 236
I0712 13:22:15.539190 140593426802496 train_utils.py:377] train in step: 237
I0712 13:22:15.592883 140593426802496 train_utils.py:377] train in step: 238
I0712 13:22:15.646970 140593426802496 train_utils.py:377] train in step: 239
I0712 13:22:15.700931 140593426802496 train_utils.py:377] train in step: 240
I0712 13:22:15.755777 140593426802496 train_utils.py:377] train in step: 241
I0712 13:22:15.810714 140593426802496 train_utils.py:377] train in step: 242
I0712 13:22:15.866161 140593426802496 train_utils.py:377] train in step: 243
I0712 13:22:15.921915 140593426802496 train_utils.py:377] train in step: 244
I0712 13:22:15.975481 140593426802496 train_utils.py:377] train in step: 245
I0712 13:22:16.028987 140593426802496 train_utils.py:377] train in step: 246
I0712 13:22:16.084554 140593426802496 train_utils.py:377] train in step: 247
I0712 13:22:16.138725 140593426802496 train_utils.py:377] train in step: 248
I0712 13:22:16.192949 140593426802496 train_utils.py:377] train in step: 249
I0712 13:22:16.247519 140593426802496 train_utils.py:377] train in step: 250
I0712 13:22:16.302317 140593426802496 train_utils.py:377] train in step: 251
I0712 13:22:16.356617 140593426802496 train_utils.py:377] train in step: 252
I0712 13:22:16.413018 140593426802496 train_utils.py:377] train in step: 253
I0712 13:22:16.467614 140593426802496 train_utils.py:377] train in step: 254
I0712 13:22:16.522063 140593426802496 train_utils.py:377] train in step: 255
I0712 13:22:16.577187 140593426802496 train_utils.py:377] train in step: 256
I0712 13:22:16.631565 140593426802496 train_utils.py:377] train in step: 257
I0712 13:22:16.685871 140593426802496 train_utils.py:377] train in step: 258
I0712 13:22:16.741029 140593426802496 train_utils.py:377] train in step: 259
I0712 13:22:16.796273 140593426802496 train_utils.py:377] train in step: 260
I0712 13:22:16.854357 140593426802496 train_utils.py:377] train in step: 261
I0712 13:22:16.909161 140593426802496 train_utils.py:377] train in step: 262
I0712 13:22:16.964127 140593426802496 train_utils.py:377] train in step: 263
I0712 13:22:17.019315 140593426802496 train_utils.py:377] train in step: 264
I0712 13:22:17.074287 140593426802496 train_utils.py:377] train in step: 265
I0712 13:22:17.130089 140593426802496 train_utils.py:377] train in step: 266
I0712 13:22:17.185862 140593426802496 train_utils.py:377] train in step: 267
I0712 13:22:17.240895 140593426802496 train_utils.py:377] train in step: 268
I0712 13:22:17.295726 140593426802496 train_utils.py:377] train in step: 269
I0712 13:22:17.350461 140593426802496 train_utils.py:377] train in step: 270
I0712 13:22:17.405559 140593426802496 train_utils.py:377] train in step: 271
I0712 13:22:17.460911 140593426802496 train_utils.py:377] train in step: 272
I0712 13:22:17.518824 140593426802496 train_utils.py:377] train in step: 273
I0712 13:22:17.574044 140593426802496 train_utils.py:377] train in step: 274
I0712 13:22:17.631053 140593426802496 train_utils.py:377] train in step: 275
I0712 13:22:17.686193 140593426802496 train_utils.py:377] train in step: 276
I0712 13:22:17.741686 140593426802496 train_utils.py:377] train in step: 277
I0712 13:22:17.798055 140593426802496 train_utils.py:377] train in step: 278
I0712 13:22:17.853073 140593426802496 train_utils.py:377] train in step: 279
I0712 13:22:17.912353 140593426802496 train_utils.py:377] train in step: 280
I0712 13:22:17.969100 140593426802496 train_utils.py:377] train in step: 281
I0712 13:22:18.023970 140593426802496 train_utils.py:377] train in step: 282
I0712 13:22:18.079039 140593426802496 train_utils.py:377] train in step: 283
I0712 13:22:18.134626 140593426802496 train_utils.py:377] train in step: 284
I0712 13:22:18.190082 140593426802496 train_utils.py:377] train in step: 285
I0712 13:22:18.245586 140593426802496 train_utils.py:377] train in step: 286
I0712 13:22:18.300868 140593426802496 train_utils.py:377] train in step: 287
I0712 13:22:18.355998 140593426802496 train_utils.py:377] train in step: 288
I0712 13:22:18.412848 140593426802496 train_utils.py:377] train in step: 289
I0712 13:22:18.470674 140593426802496 train_utils.py:377] train in step: 290
I0712 13:22:18.523710 140593426802496 train_utils.py:377] train in step: 291
I0712 13:22:18.582289 140593426802496 train_utils.py:377] train in step: 292
I0712 13:22:18.638291 140593426802496 train_utils.py:377] train in step: 293
I0712 13:22:18.700263 140593426802496 train_utils.py:377] train in step: 294
I0712 13:22:18.755116 140593426802496 train_utils.py:377] train in step: 295
I0712 13:22:18.810947 140593426802496 train_utils.py:377] train in step: 296
I0712 13:22:18.866241 140593426802496 train_utils.py:377] train in step: 297
I0712 13:22:18.922088 140593426802496 train_utils.py:377] train in step: 298
I0712 13:22:18.980322 140593426802496 train_utils.py:377] train in step: 299
I0712 13:22:19.034521 140593426802496 train_utils.py:377] train in step: 300
I0712 13:22:19.090351 140593426802496 train_utils.py:377] train in step: 301
I0712 13:22:19.146044 140593426802496 train_utils.py:377] train in step: 302
I0712 13:22:19.201878 140593426802496 train_utils.py:377] train in step: 303
I0712 13:22:19.257522 140593426802496 train_utils.py:377] train in step: 304
I0712 13:22:19.327896 140593426802496 train_utils.py:377] train in step: 305
I0712 13:22:19.383034 140593426802496 train_utils.py:377] train in step: 306
I0712 13:22:19.440435 140593426802496 train_utils.py:377] train in step: 307
I0712 13:22:19.494071 140593426802496 train_utils.py:377] train in step: 308
I0712 13:22:19.572216 140593426802496 train_utils.py:377] train in step: 309
I0712 13:22:19.628674 140593426802496 train_utils.py:377] train in step: 310
I0712 13:22:19.685421 140593426802496 train_utils.py:377] train in step: 311
I0712 13:22:19.740652 140593426802496 train_utils.py:377] train in step: 312
I0712 13:22:19.796416 140593426802496 train_utils.py:377] train in step: 313
I0712 13:22:19.852041 140593426802496 train_utils.py:377] train in step: 314
I0712 13:22:19.907767 140593426802496 train_utils.py:377] train in step: 315
I0712 13:22:19.963001 140593426802496 train_utils.py:377] train in step: 316
I0712 13:22:20.026961 140593426802496 train_utils.py:377] train in step: 317
I0712 13:22:20.082325 140593426802496 train_utils.py:377] train in step: 318
I0712 13:22:20.138216 140593426802496 train_utils.py:377] train in step: 319
I0712 13:22:20.196071 140593426802496 train_utils.py:377] train in step: 320
I0712 13:22:20.251079 140593426802496 train_utils.py:377] train in step: 321
I0712 13:22:20.306788 140593426802496 train_utils.py:377] train in step: 322
I0712 13:22:20.362858 140593426802496 train_utils.py:377] train in step: 323
I0712 13:22:20.418344 140593426802496 train_utils.py:377] train in step: 324
I0712 13:22:20.474183 140593426802496 train_utils.py:377] train in step: 325
I0712 13:22:20.529778 140593426802496 train_utils.py:377] train in step: 326
I0712 13:22:20.585886 140593426802496 train_utils.py:377] train in step: 327
I0712 13:22:20.641841 140593426802496 train_utils.py:377] train in step: 328
I0712 13:22:20.698753 140593426802496 train_utils.py:377] train in step: 329
I0712 13:22:20.756204 140593426802496 train_utils.py:377] train in step: 330
I0712 13:22:20.811707 140593426802496 train_utils.py:377] train in step: 331
I0712 13:22:20.867218 140593426802496 train_utils.py:377] train in step: 332
I0712 13:22:20.922781 140593426802496 train_utils.py:377] train in step: 333
I0712 13:22:20.978965 140593426802496 train_utils.py:377] train in step: 334
I0712 13:22:21.034333 140593426802496 train_utils.py:377] train in step: 335
I0712 13:22:21.089854 140593426802496 train_utils.py:377] train in step: 336
I0712 13:22:21.145297 140593426802496 train_utils.py:377] train in step: 337
I0712 13:22:21.201444 140593426802496 train_utils.py:377] train in step: 338
I0712 13:22:21.257159 140593426802496 train_utils.py:377] train in step: 339
I0712 13:22:21.319089 140593426802496 train_utils.py:377] train in step: 340
I0712 13:22:21.377490 140593426802496 train_utils.py:377] train in step: 341
I0712 13:22:21.432847 140593426802496 train_utils.py:377] train in step: 342
I0712 13:22:21.488757 140593426802496 train_utils.py:377] train in step: 343
I0712 13:22:21.544697 140593426802496 train_utils.py:377] train in step: 344
I0712 13:22:21.599796 140593426802496 train_utils.py:377] train in step: 345
I0712 13:22:21.655110 140593426802496 train_utils.py:377] train in step: 346
I0712 13:22:21.710636 140593426802496 train_utils.py:377] train in step: 347
I0712 13:22:21.766520 140593426802496 train_utils.py:377] train in step: 348
I0712 13:22:21.822788 140593426802496 train_utils.py:377] train in step: 349
I0712 13:22:21.877345 140593426802496 train_utils.py:377] train in step: 350
I0712 13:22:21.933257 140593426802496 train_utils.py:377] train in step: 351
I0712 13:22:21.988501 140593426802496 train_utils.py:377] train in step: 352
I0712 13:22:22.043804 140593426802496 train_utils.py:377] train in step: 353
I0712 13:22:22.103970 140593426802496 train_utils.py:377] train in step: 354
I0712 13:22:22.158403 140593426802496 train_utils.py:377] train in step: 355
I0712 13:22:22.213904 140593426802496 train_utils.py:377] train in step: 356
I0712 13:22:22.268748 140593426802496 train_utils.py:377] train in step: 357
I0712 13:22:22.324362 140593426802496 train_utils.py:377] train in step: 358
I0712 13:22:22.379373 140593426802496 train_utils.py:377] train in step: 359
I0712 13:22:22.434848 140593426802496 train_utils.py:377] train in step: 360
I0712 13:22:22.489572 140593426802496 train_utils.py:377] train in step: 361
I0712 13:22:22.545152 140593426802496 train_utils.py:377] train in step: 362
I0712 13:22:22.600729 140593426802496 train_utils.py:377] train in step: 363
I0712 13:22:22.656034 140593426802496 train_utils.py:377] train in step: 364
I0712 13:22:22.714027 140593426802496 train_utils.py:377] train in step: 365
I0712 13:22:22.767994 140593426802496 train_utils.py:377] train in step: 366
I0712 13:22:22.825447 140593426802496 train_utils.py:377] train in step: 367
I0712 13:22:22.881067 140593426802496 train_utils.py:377] train in step: 368
I0712 13:22:22.937073 140593426802496 train_utils.py:377] train in step: 369
I0712 13:22:22.991487 140593426802496 train_utils.py:377] train in step: 370
I0712 13:22:23.046626 140593426802496 train_utils.py:377] train in step: 371
I0712 13:22:23.104323 140593426802496 train_utils.py:377] train in step: 372
I0712 13:22:23.157768 140593426802496 train_utils.py:377] train in step: 373
I0712 13:22:23.212621 140593426802496 train_utils.py:377] train in step: 374
I0712 13:22:23.268070 140593426802496 train_utils.py:377] train in step: 375
I0712 13:22:23.322962 140593426802496 train_utils.py:377] train in step: 376
I0712 13:22:23.378999 140593426802496 train_utils.py:377] train in step: 377
I0712 13:22:23.434733 140593426802496 train_utils.py:377] train in step: 378
I0712 13:22:23.489602 140593426802496 train_utils.py:377] train in step: 379
I0712 13:22:23.545061 140593426802496 train_utils.py:377] train in step: 380
I0712 13:22:23.601989 140593426802496 train_utils.py:377] train in step: 381
I0712 13:22:23.657251 140593426802496 train_utils.py:377] train in step: 382
I0712 13:22:23.712292 140593426802496 train_utils.py:377] train in step: 383
I0712 13:22:23.767622 140593426802496 train_utils.py:377] train in step: 384
I0712 13:22:23.822828 140593426802496 train_utils.py:377] train in step: 385
I0712 13:22:23.877179 140593426802496 train_utils.py:377] train in step: 386
I0712 13:22:23.932640 140593426802496 train_utils.py:377] train in step: 387
I0712 13:22:23.988418 140593426802496 train_utils.py:377] train in step: 388
I0712 13:22:24.043999 140593426802496 train_utils.py:377] train in step: 389
I0712 13:22:24.099417 140593426802496 train_utils.py:377] train in step: 390
I0712 13:22:24.161828 140593426802496 train_utils.py:377] train in step: 391
I0712 13:22:24.220563 140593426802496 train_utils.py:377] train in step: 392
I0712 13:22:24.275582 140593426802496 train_utils.py:377] train in step: 393
I0712 13:22:24.331201 140593426802496 train_utils.py:377] train in step: 394
I0712 13:22:24.387111 140593426802496 train_utils.py:377] train in step: 395
I0712 13:22:24.443437 140593426802496 train_utils.py:377] train in step: 396
I0712 13:22:24.498458 140593426802496 train_utils.py:377] train in step: 397
I0712 13:22:24.554111 140593426802496 train_utils.py:377] train in step: 398
I0712 13:22:24.609750 140593426802496 train_utils.py:377] train in step: 399
I0712 13:22:24.664986 140593426802496 train_utils.py:377] train in step: 400
I0712 13:22:24.927158 140593426802496 train_utils.py:396] train in step: 400, loss: 0.6887999773025513, acc: 0.5774999856948853
I0712 13:22:28.216593 140593426802496 train_utils.py:411] eval in step: 400, loss: 0.8694, acc: 0.5050
I0712 13:22:28.219677 140593426802496 train_utils.py:421] Testing...
I0712 13:22:31.576902 140593426802496 train_utils.py:424] test in step: 400, loss: 0.9122, acc: 0.4700
I0712 13:22:31.615994 140593426802496 train_utils.py:377] train in step: 401
I0712 13:22:31.645596 140593426802496 train_utils.py:377] train in step: 402
I0712 13:22:31.700723 140593426802496 train_utils.py:377] train in step: 403
I0712 13:22:31.754722 140593426802496 train_utils.py:377] train in step: 404
I0712 13:22:31.808230 140593426802496 train_utils.py:377] train in step: 405
I0712 13:22:31.865739 140593426802496 train_utils.py:377] train in step: 406
I0712 13:22:31.917678 140593426802496 train_utils.py:377] train in step: 407
I0712 13:22:31.972698 140593426802496 train_utils.py:377] train in step: 408
I0712 13:22:32.027539 140593426802496 train_utils.py:377] train in step: 409
I0712 13:22:32.081145 140593426802496 train_utils.py:377] train in step: 410
I0712 13:22:32.136989 140593426802496 train_utils.py:377] train in step: 411
I0712 13:22:32.192247 140593426802496 train_utils.py:377] train in step: 412
I0712 13:22:32.248153 140593426802496 train_utils.py:377] train in step: 413
I0712 13:22:32.303520 140593426802496 train_utils.py:377] train in step: 414
I0712 13:22:32.358787 140593426802496 train_utils.py:377] train in step: 415
I0712 13:22:32.417619 140593426802496 train_utils.py:377] train in step: 416
I0712 13:22:32.470300 140593426802496 train_utils.py:377] train in step: 417
I0712 13:22:32.525441 140593426802496 train_utils.py:377] train in step: 418
I0712 13:22:32.580359 140593426802496 train_utils.py:377] train in step: 419
I0712 13:22:32.637189 140593426802496 train_utils.py:377] train in step: 420
I0712 13:22:32.692310 140593426802496 train_utils.py:377] train in step: 421
I0712 13:22:32.748872 140593426802496 train_utils.py:377] train in step: 422
I0712 13:22:32.803805 140593426802496 train_utils.py:377] train in step: 423
I0712 13:22:32.859337 140593426802496 train_utils.py:377] train in step: 424
I0712 13:22:32.915056 140593426802496 train_utils.py:377] train in step: 425
I0712 13:22:32.970909 140593426802496 train_utils.py:377] train in step: 426
I0712 13:22:33.025993 140593426802496 train_utils.py:377] train in step: 427
I0712 13:22:33.081695 140593426802496 train_utils.py:377] train in step: 428
I0712 13:22:33.137424 140593426802496 train_utils.py:377] train in step: 429
I0712 13:22:33.197107 140593426802496 train_utils.py:377] train in step: 430
I0712 13:22:33.252276 140593426802496 train_utils.py:377] train in step: 431
I0712 13:22:33.308010 140593426802496 train_utils.py:377] train in step: 432
I0712 13:22:33.362861 140593426802496 train_utils.py:377] train in step: 433
I0712 13:22:33.419109 140593426802496 train_utils.py:377] train in step: 434
I0712 13:22:33.474337 140593426802496 train_utils.py:377] train in step: 435
I0712 13:22:33.530696 140593426802496 train_utils.py:377] train in step: 436
I0712 13:22:33.586296 140593426802496 train_utils.py:377] train in step: 437
I0712 13:22:33.642435 140593426802496 train_utils.py:377] train in step: 438
I0712 13:22:33.697572 140593426802496 train_utils.py:377] train in step: 439
I0712 13:22:33.752337 140593426802496 train_utils.py:377] train in step: 440
I0712 13:22:33.807572 140593426802496 train_utils.py:377] train in step: 441
I0712 13:22:33.863780 140593426802496 train_utils.py:377] train in step: 442
I0712 13:22:33.919033 140593426802496 train_utils.py:377] train in step: 443
I0712 13:22:33.975129 140593426802496 train_utils.py:377] train in step: 444
I0712 13:22:34.031157 140593426802496 train_utils.py:377] train in step: 445
I0712 13:22:34.086574 140593426802496 train_utils.py:377] train in step: 446
I0712 13:22:34.145043 140593426802496 train_utils.py:377] train in step: 447
I0712 13:22:34.204500 140593426802496 train_utils.py:377] train in step: 448
I0712 13:22:34.260345 140593426802496 train_utils.py:377] train in step: 449
I0712 13:22:34.315281 140593426802496 train_utils.py:377] train in step: 450
I0712 13:22:34.371447 140593426802496 train_utils.py:377] train in step: 451
I0712 13:22:34.427049 140593426802496 train_utils.py:377] train in step: 452
I0712 13:22:34.482433 140593426802496 train_utils.py:377] train in step: 453
I0712 13:22:34.537933 140593426802496 train_utils.py:377] train in step: 454
I0712 13:22:34.592761 140593426802496 train_utils.py:377] train in step: 455
I0712 13:22:34.648058 140593426802496 train_utils.py:377] train in step: 456
I0712 13:22:34.703468 140593426802496 train_utils.py:377] train in step: 457
I0712 13:22:34.759124 140593426802496 train_utils.py:377] train in step: 458
I0712 13:22:34.815266 140593426802496 train_utils.py:377] train in step: 459
I0712 13:22:34.873236 140593426802496 train_utils.py:377] train in step: 460
I0712 13:22:34.928765 140593426802496 train_utils.py:377] train in step: 461
I0712 13:22:34.984557 140593426802496 train_utils.py:377] train in step: 462
I0712 13:22:35.039722 140593426802496 train_utils.py:377] train in step: 463
I0712 13:22:35.095392 140593426802496 train_utils.py:377] train in step: 464
I0712 13:22:35.150735 140593426802496 train_utils.py:377] train in step: 465
I0712 13:22:35.205717 140593426802496 train_utils.py:377] train in step: 466
I0712 13:22:35.261557 140593426802496 train_utils.py:377] train in step: 467
I0712 13:22:35.318770 140593426802496 train_utils.py:377] train in step: 468
I0712 13:22:35.373699 140593426802496 train_utils.py:377] train in step: 469
I0712 13:22:35.429335 140593426802496 train_utils.py:377] train in step: 470
I0712 13:22:35.497454 140593426802496 train_utils.py:377] train in step: 471
I0712 13:22:35.570505 140593426802496 train_utils.py:377] train in step: 472
I0712 13:22:35.627876 140593426802496 train_utils.py:377] train in step: 473
I0712 13:22:35.682503 140593426802496 train_utils.py:377] train in step: 474
I0712 13:22:35.743077 140593426802496 train_utils.py:377] train in step: 475
I0712 13:22:35.799299 140593426802496 train_utils.py:377] train in step: 476
I0712 13:22:35.854431 140593426802496 train_utils.py:377] train in step: 477
I0712 13:22:35.908902 140593426802496 train_utils.py:377] train in step: 478
I0712 13:22:35.964217 140593426802496 train_utils.py:377] train in step: 479
I0712 13:22:36.019608 140593426802496 train_utils.py:377] train in step: 480
I0712 13:22:36.075674 140593426802496 train_utils.py:377] train in step: 481
I0712 13:22:36.130471 140593426802496 train_utils.py:377] train in step: 482
I0712 13:22:36.186866 140593426802496 train_utils.py:377] train in step: 483
I0712 13:22:36.243108 140593426802496 train_utils.py:377] train in step: 484
I0712 13:22:36.314396 140593426802496 train_utils.py:377] train in step: 485
I0712 13:22:36.368786 140593426802496 train_utils.py:377] train in step: 486
I0712 13:22:36.424456 140593426802496 train_utils.py:377] train in step: 487
I0712 13:22:36.479136 140593426802496 train_utils.py:377] train in step: 488
I0712 13:22:36.534083 140593426802496 train_utils.py:377] train in step: 489
I0712 13:22:36.591525 140593426802496 train_utils.py:377] train in step: 490
I0712 13:22:36.646406 140593426802496 train_utils.py:377] train in step: 491
I0712 13:22:36.701830 140593426802496 train_utils.py:377] train in step: 492
I0712 13:22:36.757529 140593426802496 train_utils.py:377] train in step: 493
I0712 13:22:36.812506 140593426802496 train_utils.py:377] train in step: 494
I0712 13:22:36.868157 140593426802496 train_utils.py:377] train in step: 495
I0712 13:22:36.923343 140593426802496 train_utils.py:377] train in step: 496
I0712 13:22:36.979577 140593426802496 train_utils.py:377] train in step: 497
I0712 13:22:37.033900 140593426802496 train_utils.py:377] train in step: 498
I0712 13:22:37.088949 140593426802496 train_utils.py:377] train in step: 499
I0712 13:22:37.144129 140593426802496 train_utils.py:377] train in step: 500
I0712 13:22:37.199838 140593426802496 train_utils.py:377] train in step: 501
I0712 13:22:37.255481 140593426802496 train_utils.py:377] train in step: 502
I0712 13:22:37.310732 140593426802496 train_utils.py:377] train in step: 503
I0712 13:22:37.366190 140593426802496 train_utils.py:377] train in step: 504
I0712 13:22:37.421341 140593426802496 train_utils.py:377] train in step: 505
I0712 13:22:37.476859 140593426802496 train_utils.py:377] train in step: 506
I0712 13:22:37.532409 140593426802496 train_utils.py:377] train in step: 507
I0712 13:22:37.587578 140593426802496 train_utils.py:377] train in step: 508
I0712 13:22:37.647544 140593426802496 train_utils.py:377] train in step: 509
I0712 13:22:37.702183 140593426802496 train_utils.py:377] train in step: 510
I0712 13:22:37.758073 140593426802496 train_utils.py:377] train in step: 511
I0712 13:22:37.814169 140593426802496 train_utils.py:377] train in step: 512
I0712 13:22:37.869729 140593426802496 train_utils.py:377] train in step: 513
I0712 13:22:37.924418 140593426802496 train_utils.py:377] train in step: 514
I0712 13:22:37.979966 140593426802496 train_utils.py:377] train in step: 515
I0712 13:22:38.035791 140593426802496 train_utils.py:377] train in step: 516
I0712 13:22:38.091109 140593426802496 train_utils.py:377] train in step: 517
I0712 13:22:38.146997 140593426802496 train_utils.py:377] train in step: 518
I0712 13:22:38.202568 140593426802496 train_utils.py:377] train in step: 519
I0712 13:22:38.258413 140593426802496 train_utils.py:377] train in step: 520
I0712 13:22:38.316649 140593426802496 train_utils.py:377] train in step: 521
I0712 13:22:38.372380 140593426802496 train_utils.py:377] train in step: 522
I0712 13:22:38.427267 140593426802496 train_utils.py:377] train in step: 523
I0712 13:22:38.483521 140593426802496 train_utils.py:377] train in step: 524
I0712 13:22:38.538302 140593426802496 train_utils.py:377] train in step: 525
I0712 13:22:38.595088 140593426802496 train_utils.py:377] train in step: 526
I0712 13:22:38.650357 140593426802496 train_utils.py:377] train in step: 527
I0712 13:22:38.705899 140593426802496 train_utils.py:377] train in step: 528
I0712 13:22:38.761235 140593426802496 train_utils.py:377] train in step: 529
I0712 13:22:38.816669 140593426802496 train_utils.py:377] train in step: 530
I0712 13:22:38.872321 140593426802496 train_utils.py:377] train in step: 531
I0712 13:22:38.927809 140593426802496 train_utils.py:377] train in step: 532
I0712 13:22:38.990117 140593426802496 train_utils.py:377] train in step: 533
I0712 13:22:39.050864 140593426802496 train_utils.py:377] train in step: 534
I0712 13:22:39.110138 140593426802496 train_utils.py:377] train in step: 535
I0712 13:22:39.165558 140593426802496 train_utils.py:377] train in step: 536
I0712 13:22:39.220741 140593426802496 train_utils.py:377] train in step: 537
I0712 13:22:39.276345 140593426802496 train_utils.py:377] train in step: 538
I0712 13:22:39.331748 140593426802496 train_utils.py:377] train in step: 539
I0712 13:22:39.387339 140593426802496 train_utils.py:377] train in step: 540
I0712 13:22:39.442323 140593426802496 train_utils.py:377] train in step: 541
I0712 13:22:39.499772 140593426802496 train_utils.py:377] train in step: 542
I0712 13:22:39.553365 140593426802496 train_utils.py:377] train in step: 543
I0712 13:22:39.609664 140593426802496 train_utils.py:377] train in step: 544
I0712 13:22:39.665141 140593426802496 train_utils.py:377] train in step: 545
I0712 13:22:39.721613 140593426802496 train_utils.py:377] train in step: 546
I0712 13:22:39.778727 140593426802496 train_utils.py:377] train in step: 547
I0712 13:22:39.833669 140593426802496 train_utils.py:377] train in step: 548
I0712 13:22:39.889097 140593426802496 train_utils.py:377] train in step: 549
I0712 13:22:39.944445 140593426802496 train_utils.py:377] train in step: 550
I0712 13:22:40.000009 140593426802496 train_utils.py:377] train in step: 551
I0712 13:22:40.055338 140593426802496 train_utils.py:377] train in step: 552
I0712 13:22:40.114022 140593426802496 train_utils.py:377] train in step: 553
I0712 13:22:40.167020 140593426802496 train_utils.py:377] train in step: 554
I0712 13:22:40.223830 140593426802496 train_utils.py:377] train in step: 555
I0712 13:22:40.279798 140593426802496 train_utils.py:377] train in step: 556
I0712 13:22:40.337746 140593426802496 train_utils.py:377] train in step: 557
I0712 13:22:40.393060 140593426802496 train_utils.py:377] train in step: 558
I0712 13:22:40.449793 140593426802496 train_utils.py:377] train in step: 559
I0712 13:22:40.504212 140593426802496 train_utils.py:377] train in step: 560
I0712 13:22:40.559466 140593426802496 train_utils.py:377] train in step: 561
I0712 13:22:40.614830 140593426802496 train_utils.py:377] train in step: 562
I0712 13:22:40.670536 140593426802496 train_utils.py:377] train in step: 563
I0712 13:22:40.725392 140593426802496 train_utils.py:377] train in step: 564
I0712 13:22:40.782720 140593426802496 train_utils.py:377] train in step: 565
I0712 13:22:40.837719 140593426802496 train_utils.py:377] train in step: 566
I0712 13:22:40.894107 140593426802496 train_utils.py:377] train in step: 567
I0712 13:22:40.951821 140593426802496 train_utils.py:377] train in step: 568
I0712 13:22:41.007628 140593426802496 train_utils.py:377] train in step: 569
I0712 13:22:41.064132 140593426802496 train_utils.py:377] train in step: 570
I0712 13:22:41.122120 140593426802496 train_utils.py:377] train in step: 571
I0712 13:22:41.174868 140593426802496 train_utils.py:377] train in step: 572
I0712 13:22:41.230509 140593426802496 train_utils.py:377] train in step: 573
I0712 13:22:41.285851 140593426802496 train_utils.py:377] train in step: 574
I0712 13:22:41.342550 140593426802496 train_utils.py:377] train in step: 575
I0712 13:22:41.397560 140593426802496 train_utils.py:377] train in step: 576
I0712 13:22:41.453372 140593426802496 train_utils.py:377] train in step: 577
I0712 13:22:41.508601 140593426802496 train_utils.py:377] train in step: 578
I0712 13:22:41.565640 140593426802496 train_utils.py:377] train in step: 579
I0712 13:22:41.622656 140593426802496 train_utils.py:377] train in step: 580
I0712 13:22:41.681786 140593426802496 train_utils.py:377] train in step: 581
I0712 13:22:41.737129 140593426802496 train_utils.py:377] train in step: 582
I0712 13:22:41.794022 140593426802496 train_utils.py:377] train in step: 583
I0712 13:22:41.848994 140593426802496 train_utils.py:377] train in step: 584
I0712 13:22:41.904814 140593426802496 train_utils.py:377] train in step: 585
I0712 13:22:41.959914 140593426802496 train_utils.py:377] train in step: 586
I0712 13:22:42.014954 140593426802496 train_utils.py:377] train in step: 587
I0712 13:22:42.070500 140593426802496 train_utils.py:377] train in step: 588
I0712 13:22:42.126107 140593426802496 train_utils.py:377] train in step: 589
I0712 13:22:42.181305 140593426802496 train_utils.py:377] train in step: 590
I0712 13:22:42.237262 140593426802496 train_utils.py:377] train in step: 591
I0712 13:22:42.293469 140593426802496 train_utils.py:377] train in step: 592
I0712 13:22:42.355434 140593426802496 train_utils.py:377] train in step: 593
I0712 13:22:42.412598 140593426802496 train_utils.py:377] train in step: 594
I0712 13:22:42.469614 140593426802496 train_utils.py:377] train in step: 595
I0712 13:22:42.524883 140593426802496 train_utils.py:377] train in step: 596
I0712 13:22:42.580034 140593426802496 train_utils.py:377] train in step: 597
I0712 13:22:42.635439 140593426802496 train_utils.py:377] train in step: 598
I0712 13:22:42.690747 140593426802496 train_utils.py:377] train in step: 599
I0712 13:22:42.745932 140593426802496 train_utils.py:377] train in step: 600
I0712 13:22:42.831015 140593426802496 train_utils.py:396] train in step: 600, loss: 0.6800999641418457, acc: 0.5837999582290649
I0712 13:22:46.256882 140593426802496 train_utils.py:411] eval in step: 600, loss: 0.8388, acc: 0.5250
I0712 13:22:46.260228 140593426802496 train_utils.py:421] Testing...
I0712 13:22:49.583842 140593426802496 train_utils.py:424] test in step: 600, loss: 0.6968, acc: 0.6350
I0712 13:22:49.613276 140593426802496 train_utils.py:377] train in step: 601
I0712 13:22:49.642950 140593426802496 train_utils.py:377] train in step: 602
I0712 13:22:49.699077 140593426802496 train_utils.py:377] train in step: 603
I0712 13:22:49.753191 140593426802496 train_utils.py:377] train in step: 604
I0712 13:22:49.808019 140593426802496 train_utils.py:377] train in step: 605
I0712 13:22:49.862480 140593426802496 train_utils.py:377] train in step: 606
I0712 13:22:49.916280 140593426802496 train_utils.py:377] train in step: 607
I0712 13:22:49.970870 140593426802496 train_utils.py:377] train in step: 608
I0712 13:22:50.029729 140593426802496 train_utils.py:377] train in step: 609
I0712 13:22:50.083717 140593426802496 train_utils.py:377] train in step: 610
I0712 13:22:50.138099 140593426802496 train_utils.py:377] train in step: 611
I0712 13:22:50.192947 140593426802496 train_utils.py:377] train in step: 612
I0712 13:22:50.249339 140593426802496 train_utils.py:377] train in step: 613
I0712 13:22:50.308580 140593426802496 train_utils.py:377] train in step: 614
I0712 13:22:50.363730 140593426802496 train_utils.py:377] train in step: 615
I0712 13:22:50.420656 140593426802496 train_utils.py:377] train in step: 616
I0712 13:22:50.475958 140593426802496 train_utils.py:377] train in step: 617
I0712 13:22:50.531095 140593426802496 train_utils.py:377] train in step: 618
I0712 13:22:50.586545 140593426802496 train_utils.py:377] train in step: 619
I0712 13:22:50.641721 140593426802496 train_utils.py:377] train in step: 620
I0712 13:22:50.697453 140593426802496 train_utils.py:377] train in step: 621
I0712 13:22:50.752522 140593426802496 train_utils.py:377] train in step: 622
I0712 13:22:50.808153 140593426802496 train_utils.py:377] train in step: 623
I0712 13:22:50.863387 140593426802496 train_utils.py:377] train in step: 624
I0712 13:22:50.918801 140593426802496 train_utils.py:377] train in step: 625
I0712 13:22:50.974462 140593426802496 train_utils.py:377] train in step: 626
I0712 13:22:51.036998 140593426802496 train_utils.py:377] train in step: 627
I0712 13:22:51.092920 140593426802496 train_utils.py:377] train in step: 628
I0712 13:22:51.148705 140593426802496 train_utils.py:377] train in step: 629
I0712 13:22:51.205528 140593426802496 train_utils.py:377] train in step: 630
I0712 13:22:51.260895 140593426802496 train_utils.py:377] train in step: 631
I0712 13:22:51.316401 140593426802496 train_utils.py:377] train in step: 632
I0712 13:22:51.371829 140593426802496 train_utils.py:377] train in step: 633
I0712 13:22:51.427022 140593426802496 train_utils.py:377] train in step: 634
I0712 13:22:51.482387 140593426802496 train_utils.py:377] train in step: 635
I0712 13:22:51.537593 140593426802496 train_utils.py:377] train in step: 636
I0712 13:22:51.592863 140593426802496 train_utils.py:377] train in step: 637
I0712 13:22:51.648621 140593426802496 train_utils.py:377] train in step: 638
I0712 13:22:51.704507 140593426802496 train_utils.py:377] train in step: 639
I0712 13:22:51.769019 140593426802496 train_utils.py:377] train in step: 640
I0712 13:22:51.824194 140593426802496 train_utils.py:377] train in step: 641
I0712 13:22:51.879742 140593426802496 train_utils.py:377] train in step: 642
I0712 13:22:51.934946 140593426802496 train_utils.py:377] train in step: 643
I0712 13:22:51.990196 140593426802496 train_utils.py:377] train in step: 644
I0712 13:22:52.045532 140593426802496 train_utils.py:377] train in step: 645
I0712 13:22:52.101028 140593426802496 train_utils.py:377] train in step: 646
I0712 13:22:52.155794 140593426802496 train_utils.py:377] train in step: 647
I0712 13:22:52.211355 140593426802496 train_utils.py:377] train in step: 648
I0712 13:22:52.266834 140593426802496 train_utils.py:377] train in step: 649
I0712 13:22:52.322342 140593426802496 train_utils.py:377] train in step: 650
I0712 13:22:52.378461 140593426802496 train_utils.py:377] train in step: 651
I0712 13:22:52.434549 140593426802496 train_utils.py:377] train in step: 652
I0712 13:22:52.490151 140593426802496 train_utils.py:377] train in step: 653
I0712 13:22:52.545414 140593426802496 train_utils.py:377] train in step: 654
I0712 13:22:52.601238 140593426802496 train_utils.py:377] train in step: 655
I0712 13:22:52.656631 140593426802496 train_utils.py:377] train in step: 656
I0712 13:22:52.711844 140593426802496 train_utils.py:377] train in step: 657
I0712 13:22:52.767359 140593426802496 train_utils.py:377] train in step: 658
I0712 13:22:52.822530 140593426802496 train_utils.py:377] train in step: 659
I0712 13:22:52.878219 140593426802496 train_utils.py:377] train in step: 660
I0712 13:22:52.933768 140593426802496 train_utils.py:377] train in step: 661
I0712 13:22:52.988757 140593426802496 train_utils.py:377] train in step: 662
I0712 13:22:53.044620 140593426802496 train_utils.py:377] train in step: 663
I0712 13:22:53.100042 140593426802496 train_utils.py:377] train in step: 664
I0712 13:22:53.155827 140593426802496 train_utils.py:377] train in step: 665
I0712 13:22:53.210781 140593426802496 train_utils.py:377] train in step: 666
I0712 13:22:53.266561 140593426802496 train_utils.py:377] train in step: 667
I0712 13:22:53.321841 140593426802496 train_utils.py:377] train in step: 668
I0712 13:22:53.377324 140593426802496 train_utils.py:377] train in step: 669
I0712 13:22:53.432605 140593426802496 train_utils.py:377] train in step: 670
I0712 13:22:53.487841 140593426802496 train_utils.py:377] train in step: 671
I0712 13:22:53.543294 140593426802496 train_utils.py:377] train in step: 672
I0712 13:22:53.598489 140593426802496 train_utils.py:377] train in step: 673
I0712 13:22:53.654374 140593426802496 train_utils.py:377] train in step: 674
I0712 13:22:53.709557 140593426802496 train_utils.py:377] train in step: 675
I0712 13:22:53.765494 140593426802496 train_utils.py:377] train in step: 676
I0712 13:22:53.821039 140593426802496 train_utils.py:377] train in step: 677
I0712 13:22:53.876967 140593426802496 train_utils.py:377] train in step: 678
I0712 13:22:53.932115 140593426802496 train_utils.py:377] train in step: 679
I0712 13:22:53.986911 140593426802496 train_utils.py:377] train in step: 680
I0712 13:22:54.042366 140593426802496 train_utils.py:377] train in step: 681
I0712 13:22:54.099406 140593426802496 train_utils.py:377] train in step: 682
I0712 13:22:54.152863 140593426802496 train_utils.py:377] train in step: 683
I0712 13:22:54.208368 140593426802496 train_utils.py:377] train in step: 684
I0712 13:22:54.264071 140593426802496 train_utils.py:377] train in step: 685
I0712 13:22:54.319865 140593426802496 train_utils.py:377] train in step: 686
I0712 13:22:54.374549 140593426802496 train_utils.py:377] train in step: 687
I0712 13:22:54.430249 140593426802496 train_utils.py:377] train in step: 688
I0712 13:22:54.485571 140593426802496 train_utils.py:377] train in step: 689
I0712 13:22:54.541289 140593426802496 train_utils.py:377] train in step: 690
I0712 13:22:54.596946 140593426802496 train_utils.py:377] train in step: 691
I0712 13:22:54.652516 140593426802496 train_utils.py:377] train in step: 692
I0712 13:22:54.707456 140593426802496 train_utils.py:377] train in step: 693
I0712 13:22:54.763425 140593426802496 train_utils.py:377] train in step: 694
I0712 13:22:54.818375 140593426802496 train_utils.py:377] train in step: 695
I0712 13:22:54.874143 140593426802496 train_utils.py:377] train in step: 696
I0712 13:22:54.929216 140593426802496 train_utils.py:377] train in step: 697
I0712 13:22:54.984859 140593426802496 train_utils.py:377] train in step: 698
I0712 13:22:55.040966 140593426802496 train_utils.py:377] train in step: 699
I0712 13:22:55.097275 140593426802496 train_utils.py:377] train in step: 700
I0712 13:22:55.152966 140593426802496 train_utils.py:377] train in step: 701
I0712 13:22:55.208412 140593426802496 train_utils.py:377] train in step: 702
I0712 13:22:55.264121 140593426802496 train_utils.py:377] train in step: 703
I0712 13:22:55.319339 140593426802496 train_utils.py:377] train in step: 704
I0712 13:22:55.374693 140593426802496 train_utils.py:377] train in step: 705
I0712 13:22:55.430013 140593426802496 train_utils.py:377] train in step: 706
I0712 13:22:55.485581 140593426802496 train_utils.py:377] train in step: 707
I0712 13:22:55.541478 140593426802496 train_utils.py:377] train in step: 708
I0712 13:22:55.597298 140593426802496 train_utils.py:377] train in step: 709
I0712 13:22:55.652801 140593426802496 train_utils.py:377] train in step: 710
I0712 13:22:55.709382 140593426802496 train_utils.py:377] train in step: 711
I0712 13:22:55.764384 140593426802496 train_utils.py:377] train in step: 712
I0712 13:22:55.819890 140593426802496 train_utils.py:377] train in step: 713
I0712 13:22:55.875048 140593426802496 train_utils.py:377] train in step: 714
I0712 13:22:55.930932 140593426802496 train_utils.py:377] train in step: 715
I0712 13:22:55.986672 140593426802496 train_utils.py:377] train in step: 716
I0712 13:22:56.042150 140593426802496 train_utils.py:377] train in step: 717
I0712 13:22:56.097340 140593426802496 train_utils.py:377] train in step: 718
I0712 13:22:56.152633 140593426802496 train_utils.py:377] train in step: 719
I0712 13:22:56.211443 140593426802496 train_utils.py:377] train in step: 720
I0712 13:22:56.263691 140593426802496 train_utils.py:377] train in step: 721
I0712 13:22:56.319153 140593426802496 train_utils.py:377] train in step: 722
I0712 13:22:56.375031 140593426802496 train_utils.py:377] train in step: 723
I0712 13:22:56.430698 140593426802496 train_utils.py:377] train in step: 724
I0712 13:22:56.486051 140593426802496 train_utils.py:377] train in step: 725
I0712 13:22:56.541245 140593426802496 train_utils.py:377] train in step: 726
I0712 13:22:56.597489 140593426802496 train_utils.py:377] train in step: 727
I0712 13:22:56.652603 140593426802496 train_utils.py:377] train in step: 728
I0712 13:22:56.707305 140593426802496 train_utils.py:377] train in step: 729
I0712 13:22:56.762380 140593426802496 train_utils.py:377] train in step: 730
I0712 13:22:56.818129 140593426802496 train_utils.py:377] train in step: 731
I0712 13:22:56.873241 140593426802496 train_utils.py:377] train in step: 732
I0712 13:22:56.928814 140593426802496 train_utils.py:377] train in step: 733
I0712 13:22:56.984260 140593426802496 train_utils.py:377] train in step: 734
I0712 13:22:57.039747 140593426802496 train_utils.py:377] train in step: 735
I0712 13:22:57.101555 140593426802496 train_utils.py:377] train in step: 736
I0712 13:22:57.164498 140593426802496 train_utils.py:377] train in step: 737
I0712 13:22:57.219750 140593426802496 train_utils.py:377] train in step: 738
I0712 13:22:57.276067 140593426802496 train_utils.py:377] train in step: 739
I0712 13:22:57.331641 140593426802496 train_utils.py:377] train in step: 740
I0712 13:22:57.386628 140593426802496 train_utils.py:377] train in step: 741
I0712 13:22:57.441803 140593426802496 train_utils.py:377] train in step: 742
I0712 13:22:57.497430 140593426802496 train_utils.py:377] train in step: 743
I0712 13:22:57.553724 140593426802496 train_utils.py:377] train in step: 744
I0712 13:22:57.608513 140593426802496 train_utils.py:377] train in step: 745
I0712 13:22:57.663905 140593426802496 train_utils.py:377] train in step: 746
I0712 13:22:57.719246 140593426802496 train_utils.py:377] train in step: 747
I0712 13:22:57.776612 140593426802496 train_utils.py:377] train in step: 748
I0712 13:22:57.832052 140593426802496 train_utils.py:377] train in step: 749
I0712 13:22:57.888791 140593426802496 train_utils.py:377] train in step: 750
I0712 13:22:57.942287 140593426802496 train_utils.py:377] train in step: 751
I0712 13:22:57.997942 140593426802496 train_utils.py:377] train in step: 752
I0712 13:22:58.053046 140593426802496 train_utils.py:377] train in step: 753
I0712 13:22:58.108598 140593426802496 train_utils.py:377] train in step: 754
I0712 13:22:58.164154 140593426802496 train_utils.py:377] train in step: 755
I0712 13:22:58.219342 140593426802496 train_utils.py:377] train in step: 756
I0712 13:22:58.274710 140593426802496 train_utils.py:377] train in step: 757
I0712 13:22:58.329845 140593426802496 train_utils.py:377] train in step: 758
I0712 13:22:58.385267 140593426802496 train_utils.py:377] train in step: 759
I0712 13:22:58.441622 140593426802496 train_utils.py:377] train in step: 760
I0712 13:22:58.497872 140593426802496 train_utils.py:377] train in step: 761
I0712 13:22:58.553589 140593426802496 train_utils.py:377] train in step: 762
I0712 13:22:58.608327 140593426802496 train_utils.py:377] train in step: 763
I0712 13:22:58.663256 140593426802496 train_utils.py:377] train in step: 764
I0712 13:22:58.719325 140593426802496 train_utils.py:377] train in step: 765
I0712 13:22:58.775835 140593426802496 train_utils.py:377] train in step: 766
I0712 13:22:58.830663 140593426802496 train_utils.py:377] train in step: 767
I0712 13:22:58.886178 140593426802496 train_utils.py:377] train in step: 768
I0712 13:22:58.942053 140593426802496 train_utils.py:377] train in step: 769
I0712 13:22:58.996993 140593426802496 train_utils.py:377] train in step: 770
I0712 13:22:59.052673 140593426802496 train_utils.py:377] train in step: 771
I0712 13:22:59.108635 140593426802496 train_utils.py:377] train in step: 772
I0712 13:22:59.179002 140593426802496 train_utils.py:377] train in step: 773
I0712 13:22:59.234217 140593426802496 train_utils.py:377] train in step: 774
I0712 13:22:59.289694 140593426802496 train_utils.py:377] train in step: 775
I0712 13:22:59.344883 140593426802496 train_utils.py:377] train in step: 776
I0712 13:22:59.402785 140593426802496 train_utils.py:377] train in step: 777
I0712 13:22:59.458636 140593426802496 train_utils.py:377] train in step: 778
I0712 13:22:59.513921 140593426802496 train_utils.py:377] train in step: 779
I0712 13:22:59.570011 140593426802496 train_utils.py:377] train in step: 780
I0712 13:22:59.624638 140593426802496 train_utils.py:377] train in step: 781
I0712 13:22:59.680140 140593426802496 train_utils.py:377] train in step: 782
I0712 13:22:59.735658 140593426802496 train_utils.py:377] train in step: 783
I0712 13:22:59.791570 140593426802496 train_utils.py:377] train in step: 784
I0712 13:22:59.860918 140593426802496 train_utils.py:377] train in step: 785
I0712 13:22:59.919758 140593426802496 train_utils.py:377] train in step: 786
I0712 13:22:59.978845 140593426802496 train_utils.py:377] train in step: 787
I0712 13:23:00.041009 140593426802496 train_utils.py:377] train in step: 788
I0712 13:23:00.096201 140593426802496 train_utils.py:377] train in step: 789
I0712 13:23:00.151751 140593426802496 train_utils.py:377] train in step: 790
I0712 13:23:00.206977 140593426802496 train_utils.py:377] train in step: 791
I0712 13:23:00.262444 140593426802496 train_utils.py:377] train in step: 792
I0712 13:23:00.318217 140593426802496 train_utils.py:377] train in step: 793
I0712 13:23:00.373548 140593426802496 train_utils.py:377] train in step: 794
I0712 13:23:00.429188 140593426802496 train_utils.py:377] train in step: 795
I0712 13:23:00.484472 140593426802496 train_utils.py:377] train in step: 796
I0712 13:23:00.540182 140593426802496 train_utils.py:377] train in step: 797
I0712 13:23:00.596472 140593426802496 train_utils.py:377] train in step: 798
I0712 13:23:00.651638 140593426802496 train_utils.py:377] train in step: 799
I0712 13:23:00.707079 140593426802496 train_utils.py:377] train in step: 800
I0712 13:23:00.791132 140593426802496 train_utils.py:396] train in step: 800, loss: 0.6638999581336975, acc: 0.6225000023841858
I0712 13:23:04.076577 140593426802496 train_utils.py:411] eval in step: 800, loss: 0.6925, acc: 0.5050
I0712 13:23:04.080518 140593426802496 train_utils.py:421] Testing...
I0712 13:23:07.478704 140593426802496 train_utils.py:424] test in step: 800, loss: 0.6891, acc: 0.5200
I0712 13:23:07.506866 140593426802496 train_utils.py:377] train in step: 801
I0712 13:23:07.537407 140593426802496 train_utils.py:377] train in step: 802
I0712 13:23:07.592127 140593426802496 train_utils.py:377] train in step: 803
I0712 13:23:07.647664 140593426802496 train_utils.py:377] train in step: 804
I0712 13:23:07.702686 140593426802496 train_utils.py:377] train in step: 805
I0712 13:23:07.761912 140593426802496 train_utils.py:377] train in step: 806
I0712 13:23:07.817750 140593426802496 train_utils.py:377] train in step: 807
I0712 13:23:07.873296 140593426802496 train_utils.py:377] train in step: 808
I0712 13:23:07.929504 140593426802496 train_utils.py:377] train in step: 809
I0712 13:23:07.987300 140593426802496 train_utils.py:377] train in step: 810
I0712 13:23:08.043098 140593426802496 train_utils.py:377] train in step: 811
I0712 13:23:08.098598 140593426802496 train_utils.py:377] train in step: 812
I0712 13:23:08.154067 140593426802496 train_utils.py:377] train in step: 813
I0712 13:23:08.209116 140593426802496 train_utils.py:377] train in step: 814
I0712 13:23:08.264554 140593426802496 train_utils.py:377] train in step: 815
I0712 13:23:08.320821 140593426802496 train_utils.py:377] train in step: 816
I0712 13:23:08.376497 140593426802496 train_utils.py:377] train in step: 817
I0712 13:23:08.430865 140593426802496 train_utils.py:377] train in step: 818
I0712 13:23:08.487477 140593426802496 train_utils.py:377] train in step: 819
I0712 13:23:08.543083 140593426802496 train_utils.py:377] train in step: 820
I0712 13:23:08.598571 140593426802496 train_utils.py:377] train in step: 821
I0712 13:23:08.666713 140593426802496 train_utils.py:377] train in step: 822
I0712 13:23:08.728295 140593426802496 train_utils.py:377] train in step: 823
I0712 13:23:08.784105 140593426802496 train_utils.py:377] train in step: 824
I0712 13:23:08.839486 140593426802496 train_utils.py:377] train in step: 825
I0712 13:23:08.894294 140593426802496 train_utils.py:377] train in step: 826
I0712 13:23:08.949874 140593426802496 train_utils.py:377] train in step: 827
I0712 13:23:09.005689 140593426802496 train_utils.py:377] train in step: 828
I0712 13:23:09.060678 140593426802496 train_utils.py:377] train in step: 829
I0712 13:23:09.116579 140593426802496 train_utils.py:377] train in step: 830
I0712 13:23:09.171894 140593426802496 train_utils.py:377] train in step: 831
I0712 13:23:09.233679 140593426802496 train_utils.py:377] train in step: 832
I0712 13:23:09.290288 140593426802496 train_utils.py:377] train in step: 833
I0712 13:23:09.349514 140593426802496 train_utils.py:377] train in step: 834
I0712 13:23:09.413752 140593426802496 train_utils.py:377] train in step: 835
I0712 13:23:09.470492 140593426802496 train_utils.py:377] train in step: 836
I0712 13:23:09.526903 140593426802496 train_utils.py:377] train in step: 837
I0712 13:23:09.582763 140593426802496 train_utils.py:377] train in step: 838
I0712 13:23:09.638446 140593426802496 train_utils.py:377] train in step: 839
I0712 13:23:09.693007 140593426802496 train_utils.py:377] train in step: 840
I0712 13:23:09.748531 140593426802496 train_utils.py:377] train in step: 841
I0712 13:23:09.803356 140593426802496 train_utils.py:377] train in step: 842
I0712 13:23:09.858883 140593426802496 train_utils.py:377] train in step: 843
I0712 13:23:09.914526 140593426802496 train_utils.py:377] train in step: 844
I0712 13:23:09.972033 140593426802496 train_utils.py:377] train in step: 845
I0712 13:23:10.027202 140593426802496 train_utils.py:377] train in step: 846
I0712 13:23:10.081738 140593426802496 train_utils.py:377] train in step: 847
I0712 13:23:10.136914 140593426802496 train_utils.py:377] train in step: 848
I0712 13:23:10.192365 140593426802496 train_utils.py:377] train in step: 849
I0712 13:23:10.247299 140593426802496 train_utils.py:377] train in step: 850
I0712 13:23:10.302376 140593426802496 train_utils.py:377] train in step: 851
I0712 13:23:10.358388 140593426802496 train_utils.py:377] train in step: 852
I0712 13:23:10.414863 140593426802496 train_utils.py:377] train in step: 853
I0712 13:23:10.469882 140593426802496 train_utils.py:377] train in step: 854
I0712 13:23:10.525499 140593426802496 train_utils.py:377] train in step: 855
I0712 13:23:10.580663 140593426802496 train_utils.py:377] train in step: 856
I0712 13:23:10.636441 140593426802496 train_utils.py:377] train in step: 857
I0712 13:23:10.691648 140593426802496 train_utils.py:377] train in step: 858
I0712 13:23:10.747076 140593426802496 train_utils.py:377] train in step: 859
I0712 13:23:10.802446 140593426802496 train_utils.py:377] train in step: 860
I0712 13:23:10.858783 140593426802496 train_utils.py:377] train in step: 861
I0712 13:23:10.914193 140593426802496 train_utils.py:377] train in step: 862
I0712 13:23:10.969132 140593426802496 train_utils.py:377] train in step: 863
I0712 13:23:11.024467 140593426802496 train_utils.py:377] train in step: 864
I0712 13:23:11.080297 140593426802496 train_utils.py:377] train in step: 865
I0712 13:23:11.135491 140593426802496 train_utils.py:377] train in step: 866
I0712 13:23:11.190798 140593426802496 train_utils.py:377] train in step: 867
I0712 13:23:11.246058 140593426802496 train_utils.py:377] train in step: 868
I0712 13:23:11.301899 140593426802496 train_utils.py:377] train in step: 869
I0712 13:23:11.357262 140593426802496 train_utils.py:377] train in step: 870
I0712 13:23:11.413133 140593426802496 train_utils.py:377] train in step: 871
I0712 13:23:11.469164 140593426802496 train_utils.py:377] train in step: 872
I0712 13:23:11.524312 140593426802496 train_utils.py:377] train in step: 873
I0712 13:23:11.579069 140593426802496 train_utils.py:377] train in step: 874
I0712 13:23:11.634471 140593426802496 train_utils.py:377] train in step: 875
I0712 13:23:11.690027 140593426802496 train_utils.py:377] train in step: 876
I0712 13:23:11.745547 140593426802496 train_utils.py:377] train in step: 877
I0712 13:23:11.800987 140593426802496 train_utils.py:377] train in step: 878
I0712 13:23:11.856468 140593426802496 train_utils.py:377] train in step: 879
I0712 13:23:11.912016 140593426802496 train_utils.py:377] train in step: 880
I0712 13:23:11.966982 140593426802496 train_utils.py:377] train in step: 881
I0712 13:23:12.023161 140593426802496 train_utils.py:377] train in step: 882
I0712 13:23:12.082268 140593426802496 train_utils.py:377] train in step: 883
I0712 13:23:12.137825 140593426802496 train_utils.py:377] train in step: 884
I0712 13:23:12.193537 140593426802496 train_utils.py:377] train in step: 885
I0712 13:23:12.249144 140593426802496 train_utils.py:377] train in step: 886
I0712 13:23:12.304363 140593426802496 train_utils.py:377] train in step: 887
I0712 13:23:12.360555 140593426802496 train_utils.py:377] train in step: 888
I0712 13:23:12.415896 140593426802496 train_utils.py:377] train in step: 889
I0712 13:23:12.470829 140593426802496 train_utils.py:377] train in step: 890
I0712 13:23:12.526303 140593426802496 train_utils.py:377] train in step: 891
I0712 13:23:12.581562 140593426802496 train_utils.py:377] train in step: 892
I0712 13:23:12.637107 140593426802496 train_utils.py:377] train in step: 893
I0712 13:23:12.692436 140593426802496 train_utils.py:377] train in step: 894
I0712 13:23:12.763319 140593426802496 train_utils.py:377] train in step: 895
I0712 13:23:12.834552 140593426802496 train_utils.py:377] train in step: 896
I0712 13:23:12.889839 140593426802496 train_utils.py:377] train in step: 897
I0712 13:23:12.944580 140593426802496 train_utils.py:377] train in step: 898
I0712 13:23:13.001164 140593426802496 train_utils.py:377] train in step: 899
I0712 13:23:13.058216 140593426802496 train_utils.py:377] train in step: 900
I0712 13:23:13.119028 140593426802496 train_utils.py:377] train in step: 901
I0712 13:23:13.175221 140593426802496 train_utils.py:377] train in step: 902
I0712 13:23:13.231998 140593426802496 train_utils.py:377] train in step: 903
I0712 13:23:13.287466 140593426802496 train_utils.py:377] train in step: 904
I0712 13:23:13.342484 140593426802496 train_utils.py:377] train in step: 905
I0712 13:23:13.398082 140593426802496 train_utils.py:377] train in step: 906
I0712 13:23:13.468099 140593426802496 train_utils.py:377] train in step: 907
I0712 13:23:13.522859 140593426802496 train_utils.py:377] train in step: 908
I0712 13:23:13.580693 140593426802496 train_utils.py:377] train in step: 909
I0712 13:23:13.645346 140593426802496 train_utils.py:377] train in step: 910
I0712 13:23:13.700706 140593426802496 train_utils.py:377] train in step: 911
I0712 13:23:13.756037 140593426802496 train_utils.py:377] train in step: 912
I0712 13:23:13.811931 140593426802496 train_utils.py:377] train in step: 913
I0712 13:23:13.867223 140593426802496 train_utils.py:377] train in step: 914
I0712 13:23:13.922547 140593426802496 train_utils.py:377] train in step: 915
I0712 13:23:13.978211 140593426802496 train_utils.py:377] train in step: 916
I0712 13:23:14.034476 140593426802496 train_utils.py:377] train in step: 917
I0712 13:23:14.089998 140593426802496 train_utils.py:377] train in step: 918
I0712 13:23:14.145875 140593426802496 train_utils.py:377] train in step: 919
I0712 13:23:14.202203 140593426802496 train_utils.py:377] train in step: 920
I0712 13:23:14.257610 140593426802496 train_utils.py:377] train in step: 921
I0712 13:23:14.312933 140593426802496 train_utils.py:377] train in step: 922
I0712 13:23:14.369148 140593426802496 train_utils.py:377] train in step: 923
I0712 13:23:14.424120 140593426802496 train_utils.py:377] train in step: 924
I0712 13:23:14.480073 140593426802496 train_utils.py:377] train in step: 925
I0712 13:23:14.535985 140593426802496 train_utils.py:377] train in step: 926
I0712 13:23:14.591519 140593426802496 train_utils.py:377] train in step: 927
I0712 13:23:14.647513 140593426802496 train_utils.py:377] train in step: 928
I0712 13:23:14.702960 140593426802496 train_utils.py:377] train in step: 929
I0712 13:23:14.758265 140593426802496 train_utils.py:377] train in step: 930
I0712 13:23:14.822594 140593426802496 train_utils.py:377] train in step: 931
I0712 13:23:14.875890 140593426802496 train_utils.py:377] train in step: 932
I0712 13:23:14.931422 140593426802496 train_utils.py:377] train in step: 933
I0712 13:23:14.986496 140593426802496 train_utils.py:377] train in step: 934
I0712 13:23:15.042235 140593426802496 train_utils.py:377] train in step: 935
I0712 13:23:15.097702 140593426802496 train_utils.py:377] train in step: 936
I0712 13:23:15.153323 140593426802496 train_utils.py:377] train in step: 937
I0712 13:23:15.209009 140593426802496 train_utils.py:377] train in step: 938
I0712 13:23:15.264053 140593426802496 train_utils.py:377] train in step: 939
I0712 13:23:15.319298 140593426802496 train_utils.py:377] train in step: 940
I0712 13:23:15.374660 140593426802496 train_utils.py:377] train in step: 941
I0712 13:23:15.430645 140593426802496 train_utils.py:377] train in step: 942
I0712 13:23:15.486642 140593426802496 train_utils.py:377] train in step: 943
I0712 13:23:15.541369 140593426802496 train_utils.py:377] train in step: 944
I0712 13:23:15.597139 140593426802496 train_utils.py:377] train in step: 945
I0712 13:23:15.652708 140593426802496 train_utils.py:377] train in step: 946
I0712 13:23:15.708209 140593426802496 train_utils.py:377] train in step: 947
I0712 13:23:15.763785 140593426802496 train_utils.py:377] train in step: 948
I0712 13:23:15.819055 140593426802496 train_utils.py:377] train in step: 949
I0712 13:23:15.874379 140593426802496 train_utils.py:377] train in step: 950
I0712 13:23:15.929774 140593426802496 train_utils.py:377] train in step: 951
I0712 13:23:15.985724 140593426802496 train_utils.py:377] train in step: 952
I0712 13:23:16.040747 140593426802496 train_utils.py:377] train in step: 953
I0712 13:23:16.096509 140593426802496 train_utils.py:377] train in step: 954
I0712 13:23:16.151818 140593426802496 train_utils.py:377] train in step: 955
I0712 13:23:16.207288 140593426802496 train_utils.py:377] train in step: 956
I0712 13:23:16.262563 140593426802496 train_utils.py:377] train in step: 957
I0712 13:23:16.317924 140593426802496 train_utils.py:377] train in step: 958
I0712 13:23:16.373342 140593426802496 train_utils.py:377] train in step: 959
I0712 13:23:16.428888 140593426802496 train_utils.py:377] train in step: 960
I0712 13:23:16.485080 140593426802496 train_utils.py:377] train in step: 961
I0712 13:23:16.540190 140593426802496 train_utils.py:377] train in step: 962
I0712 13:23:16.596458 140593426802496 train_utils.py:377] train in step: 963
I0712 13:23:16.651293 140593426802496 train_utils.py:377] train in step: 964
I0712 13:23:16.706488 140593426802496 train_utils.py:377] train in step: 965
I0712 13:23:16.761847 140593426802496 train_utils.py:377] train in step: 966
I0712 13:23:16.817520 140593426802496 train_utils.py:377] train in step: 967
I0712 13:23:16.873337 140593426802496 train_utils.py:377] train in step: 968
I0712 13:23:16.929008 140593426802496 train_utils.py:377] train in step: 969
I0712 13:23:16.984280 140593426802496 train_utils.py:377] train in step: 970
I0712 13:23:17.040140 140593426802496 train_utils.py:377] train in step: 971
I0712 13:23:17.094651 140593426802496 train_utils.py:377] train in step: 972
I0712 13:23:17.150744 140593426802496 train_utils.py:377] train in step: 973
I0712 13:23:17.206019 140593426802496 train_utils.py:377] train in step: 974
I0712 13:23:17.261390 140593426802496 train_utils.py:377] train in step: 975
I0712 13:23:17.316693 140593426802496 train_utils.py:377] train in step: 976
I0712 13:23:17.372526 140593426802496 train_utils.py:377] train in step: 977
I0712 13:23:17.427852 140593426802496 train_utils.py:377] train in step: 978
I0712 13:23:17.483889 140593426802496 train_utils.py:377] train in step: 979
I0712 13:23:17.539934 140593426802496 train_utils.py:377] train in step: 980
I0712 13:23:17.594704 140593426802496 train_utils.py:377] train in step: 981
I0712 13:23:17.650501 140593426802496 train_utils.py:377] train in step: 982
I0712 13:23:17.705693 140593426802496 train_utils.py:377] train in step: 983
I0712 13:23:17.761072 140593426802496 train_utils.py:377] train in step: 984
I0712 13:23:17.816782 140593426802496 train_utils.py:377] train in step: 985
I0712 13:23:17.871941 140593426802496 train_utils.py:377] train in step: 986
I0712 13:23:17.927207 140593426802496 train_utils.py:377] train in step: 987
I0712 13:23:17.982589 140593426802496 train_utils.py:377] train in step: 988
I0712 13:23:18.037532 140593426802496 train_utils.py:377] train in step: 989
I0712 13:23:18.093090 140593426802496 train_utils.py:377] train in step: 990
I0712 13:23:18.149943 140593426802496 train_utils.py:377] train in step: 991
I0712 13:23:18.204838 140593426802496 train_utils.py:377] train in step: 992
I0712 13:23:18.260259 140593426802496 train_utils.py:377] train in step: 993
I0712 13:23:18.315445 140593426802496 train_utils.py:377] train in step: 994
I0712 13:23:18.371834 140593426802496 train_utils.py:377] train in step: 995
I0712 13:23:18.427073 140593426802496 train_utils.py:377] train in step: 996
I0712 13:23:18.482196 140593426802496 train_utils.py:377] train in step: 997
I0712 13:23:18.537325 140593426802496 train_utils.py:377] train in step: 998
I0712 13:23:18.592912 140593426802496 train_utils.py:377] train in step: 999
I0712 13:23:18.648298 140593426802496 train_utils.py:377] train in step: 1000
I0712 13:23:18.653213 140593426802496 checkpoints.py:120] Saving checkpoint at step: 1000
I0712 13:23:18.766875 140593426802496 checkpoints.py:149] Saved checkpoint at trained_models/matching/reformer/checkpoint_1000
I0712 13:23:18.810690 140593426802496 train_utils.py:396] train in step: 1000, loss: 0.659500002861023, acc: 0.6274999976158142
I0712 13:23:22.077869 140593426802496 train_utils.py:411] eval in step: 1000, loss: 0.6582, acc: 0.5950
I0712 13:23:22.081849 140593426802496 train_utils.py:421] Testing...
I0712 13:23:25.453539 140593426802496 train_utils.py:424] test in step: 1000, loss: 0.6853, acc: 0.5950
